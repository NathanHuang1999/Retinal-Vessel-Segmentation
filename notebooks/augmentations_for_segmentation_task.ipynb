{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "augmentations-for-segmentation-task.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V-v9qgSaT1kh"
      },
      "source": [
        "# Mount Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N718mlLeFFcz"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZRSXyN0hT6_5"
      },
      "source": [
        "# Install Libraries and Import"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oYGDWktKFyV8"
      },
      "source": [
        "%%capture\n",
        "!pip install clodsa\n",
        "!pip install -q -U albumentations"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oFBTiz1zvb92"
      },
      "source": [
        "!pip uninstall imgaug"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k3Dz_7HrwsA1"
      },
      "source": [
        "%%capture\n",
        "!pip install git+https://github.com/aleju/imgaug.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yi0-7WwmHOOP"
      },
      "source": [
        "from matplotlib import pyplot as plt\n",
        "from clodsa.augmentors.augmentorFactory import createAugmentor\n",
        "from clodsa.transformers.transformerFactory import transformerGenerator\n",
        "from clodsa.techniques.techniqueFactory import createTechnique\n",
        "import random\n",
        "import cv2\n",
        "import albumentations as A\n",
        "import imageio\n",
        "import imgaug as ia\n",
        "import imgaug.augmenters as iaa\n",
        "import os "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jWIGAkfdUcyz"
      },
      "source": [
        "# CLoDSA"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bXbgFPmUZisv"
      },
      "source": [
        "## Dropout"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mIbahpcnlRp2"
      },
      "source": [
        "def apply_dropout(input_path, output_path, percentages):\n",
        "  '''\n",
        "  - input_path -> folder tree should be like that : input_path-->|\n",
        "                                                                 |-> images\n",
        "                                                                 |-> labels\n",
        "\n",
        "  - output_path -> this is the directory that will store the results\n",
        "\n",
        "  - angels -> this should be a list that includes the angels that you want to rotate images and labels.\n",
        "  '''\n",
        "  PROBLEM = \"semantic_segmentation\"\n",
        "  ANNOTATION_MODE = \"folders\"\n",
        "  INPUT_PATH = input_path + \"/\"\n",
        "  GENERATION_MODE = \"linear\"\n",
        "  OUTPUT_MODE = \"folders\"\n",
        "  OUTPUT_PATH= output_path + \"/\"\n",
        "  LABELS_EXTENSION = \".png\"\n",
        "\n",
        "  augmentor = createAugmentor(PROBLEM,ANNOTATION_MODE,OUTPUT_MODE,GENERATION_MODE,INPUT_PATH,{\"outputPath\":OUTPUT_PATH,\"labelsExtension\":LABELS_EXTENSION})\n",
        "\n",
        "  transformer = transformerGenerator(PROBLEM)\n",
        "\n",
        "  for percentage in percentages:\n",
        "    dropout = createTechnique(\"dropout\", {\"percentage\" : percentage})\n",
        "    augmentor.addTransformer(transformer(dropout))\n",
        "  \n",
        "  augmentor.applyAugmentation()\n",
        "  print(\"Dropout results were saved given directory.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PS1gDvjLldVp"
      },
      "source": [
        "# 0.05, 0,1 should be in seperate folders\n",
        "apply_dropout(\"/content/drive/MyDrive/AI_Projects/STARE/png_data/train\",\n",
        "               \"/content/drive/MyDrive/AI_Projects/STARE/png_data/dropout\",\n",
        "               [0.1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ObSsGPoJnKad"
      },
      "source": [
        "## Gamma Correction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wMuY2zgTGpeq"
      },
      "source": [
        "def apply_gamma_correction(input_path, output_path, gammas):\n",
        "  '''\n",
        "  - input_path -> folder tree should be like that : input_path-->|\n",
        "                                                                 |-> images\n",
        "                                                                 |-> labels\n",
        "\n",
        "  - output_path -> this is the directory that will store the results\n",
        "\n",
        "  - angels -> this should be a list that includes the angels that you want to rotate images and labels.\n",
        "  '''\n",
        "  PROBLEM = \"semantic_segmentation\"\n",
        "  ANNOTATION_MODE = \"folders\"\n",
        "  INPUT_PATH = input_path + \"/\"\n",
        "  GENERATION_MODE = \"linear\"\n",
        "  OUTPUT_MODE = \"folders\"\n",
        "  OUTPUT_PATH= output_path + \"/\"\n",
        "  LABELS_EXTENSION = \".png\"\n",
        "\n",
        "  augmentor = createAugmentor(PROBLEM,ANNOTATION_MODE,OUTPUT_MODE,GENERATION_MODE,INPUT_PATH,{\"outputPath\":OUTPUT_PATH,\"labelsExtension\":LABELS_EXTENSION})\n",
        "\n",
        "  transformer = transformerGenerator(PROBLEM)\n",
        "\n",
        "  for gamma in gammas:\n",
        "    gamma_t = createTechnique(\"gamma\", {\"gamma\" : gamma})\n",
        "    augmentor.addTransformer(transformer(gamma_t))\n",
        "  \n",
        "  augmentor.applyAugmentation()\n",
        "  print(\"Gamma correction results were saved given directory.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kPwHK2trmLKj"
      },
      "source": [
        "#1.5, 2 should be in seperate folders\n",
        "apply_gamma_correction(\"/content/drive/MyDrive/AI_Projects/STARE/png_data/train\",\n",
        "               \"/content/drive/MyDrive/AI_Projects/STARE/png_data/gamma_correction05\",\n",
        "               [0.5])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kPRHORXYnOUS"
      },
      "source": [
        "##Â White Noise"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ysgW42lbnMoL"
      },
      "source": [
        "def apply_white_noise(input_path, output_path, sd):\n",
        "  '''\n",
        "  - input_path -> folder tree should be like that : input_path-->|\n",
        "                                                                 |-> images\n",
        "                                                                 |-> labels\n",
        "\n",
        "  - output_path -> this is the directory that will store the results\n",
        "\n",
        "  - angels -> this should be a list that includes the angels that you want to rotate images and labels.\n",
        "  '''\n",
        "  PROBLEM = \"semantic_segmentation\"\n",
        "  ANNOTATION_MODE = \"folders\"\n",
        "  INPUT_PATH = input_path + \"/\"\n",
        "  GENERATION_MODE = \"linear\"\n",
        "  OUTPUT_MODE = \"folders\"\n",
        "  OUTPUT_PATH= output_path + \"/\"\n",
        "  LABELS_EXTENSION = \".png\"\n",
        "\n",
        "  augmentor = createAugmentor(PROBLEM,ANNOTATION_MODE,OUTPUT_MODE,GENERATION_MODE,INPUT_PATH,{\"outputPath\":OUTPUT_PATH,\"labelsExtension\":LABELS_EXTENSION})\n",
        "\n",
        "  transformer = transformerGenerator(PROBLEM)\n",
        "\n",
        "  for sigma in sd:\n",
        "    white_noise = createTechnique(\"gaussian_noise\", {\"mean\" : 0,\"sigma\":sigma})\n",
        "    augmentor.addTransformer(transformer(white_noise))\n",
        "  \n",
        "  augmentor.applyAugmentation()\n",
        "  print(\"White noise results were saved given directory.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hS23LUg1njup"
      },
      "source": [
        "apply_white_noise(\"/content/drive/MyDrive/AI_Projects/STARE/png_data/train\",\n",
        "               \"/content/drive/MyDrive/AI_Projects/STARE/png_data/white_noise\",\n",
        "               [10])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Rl2UpMTbOZG"
      },
      "source": [
        "## Equalize Histogram"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YdCkpuAVbOZG"
      },
      "source": [
        " def apply_eqhisto(input_path, output_path):\n",
        "  PROBLEM = \"semantic_segmentation\"\n",
        "  ANNOTATION_MODE = \"folders\"\n",
        "  INPUT_PATH = input_path + \"/\"\n",
        "  GENERATION_MODE = \"linear\"\n",
        "  OUTPUT_MODE = \"folders\"\n",
        "  OUTPUT_PATH= output_path + \"/\"\n",
        "  LABELS_EXTENSION = \".png\"\n",
        "\n",
        "  augmentor = createAugmentor(PROBLEM,ANNOTATION_MODE,OUTPUT_MODE,GENERATION_MODE,INPUT_PATH,{\"outputPath\":OUTPUT_PATH,\"labelsExtension\":LABELS_EXTENSION})\n",
        "\n",
        "  transformer = transformerGenerator(PROBLEM)\n",
        "  equalize = createTechnique(\"equalize_histogram\",{})\n",
        "  augmentor.addTransformer(transformer(equalize)) \n",
        "  augmentor.applyAugmentation()\n",
        "\n",
        "  print(\"Equalize histogram results were saved given directory.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NYaFZWwAbOZH"
      },
      "source": [
        "apply_eqhisto(\"/content/drive/MyDrive/AI_Projects/STARE/png_data/train\", \n",
        "              \"/content/drive/MyDrive/AI_Projects/STARE/png_data/eq_hist\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GUNqb-vkbhFp"
      },
      "source": [
        "## Blurring"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bN3xEb3lbhFs"
      },
      "source": [
        "def aug_blurring(input_path, output_path, blurr:list):\n",
        "  PROBLEM = \"semantic_segmentation\"\n",
        "  ANNOTATION_MODE = \"folders\"\n",
        "  INPUT_PATH = input_path + \"/\"\n",
        "  GENERATION_MODE = \"linear\"\n",
        "  OUTPUT_MODE = \"folders\"\n",
        "  OUTPUT_PATH= output_path + \"/\"\n",
        "  LABELS_EXTENSION = \".png\"\n",
        "\n",
        "  augmentor = createAugmentor(PROBLEM,ANNOTATION_MODE,OUTPUT_MODE,GENERATION_MODE,INPUT_PATH,{\"outputPath\":OUTPUT_PATH,\"labelsExtension\":LABELS_EXTENSION})\n",
        "  transformer = transformerGenerator(PROBLEM)\n",
        "\n",
        "  for ker in blurr:\n",
        "    blur = createTechnique(\"blurring\", {\"kernel\" : ker})\n",
        "    augmentor.addTransformer(transformer(blur))\n",
        "    print(\"Blurring for kernel = {} is done\".format(ker))\n",
        "  \n",
        "  augmentor.applyAugmentation()\n",
        "  print(\"Augmentation results were saved given directory.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3SCEH6P2bhFs"
      },
      "source": [
        "#3, 5 should be in seperate folders\n",
        "aug_blurring(\"/content/drive/MyDrive/AI_Projects/STARE/png_data/train\",\n",
        "             \"/content/drive/MyDrive/AI_Projects/STARE/png_data/blurring5\", [5])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nlNVPKGL6q-w"
      },
      "source": [
        "## Elastic Deformation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7yqvJ9ya4zrI"
      },
      "source": [
        "def apply_elastic_deformation(input_path, output_path, alpha = 5, sigma = 0.05):\n",
        "  '''\n",
        "  - input_path -> folder tree should be like that : input_path-->|\n",
        "                                                                 |-> images\n",
        "                                                                 |-> labels\n",
        "\n",
        "  - output_path -> this is the directory that will store the results\n",
        "\n",
        "  - angels -> this should be a list that includes the angels that you want to rotate images and labels.\n",
        "  '''\n",
        "  PROBLEM = \"semantic_segmentation\"\n",
        "  ANNOTATION_MODE = \"folders\"\n",
        "  INPUT_PATH = input_path + \"/\"\n",
        "  GENERATION_MODE = \"linear\"\n",
        "  OUTPUT_MODE = \"folders\"\n",
        "  OUTPUT_PATH= output_path + \"/\"\n",
        "  LABELS_EXTENSION = \".png\"\n",
        "\n",
        "  augmentor = createAugmentor(PROBLEM,ANNOTATION_MODE,OUTPUT_MODE,GENERATION_MODE,INPUT_PATH,{\"outputPath\":OUTPUT_PATH,\"labelsExtension\":LABELS_EXTENSION})\n",
        "\n",
        "  transformer = transformerGenerator(PROBLEM)\n",
        "\n",
        "  rotate = createTechnique(\"elastic\", {\"alpha\" : alpha, \"sigma\" : sigma})\n",
        "  augmentor.addTransformer(transformer(rotate))\n",
        "\n",
        "  augmentor.applyAugmentation()\n",
        "  print(\"Elastic deformation results were saved given directory.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bTl_aNL_5rAN"
      },
      "source": [
        "apply_elastic_deformation('/content/drive/MyDrive/AI_Projects/STARE/png_data/train',\n",
        "                          '/content/drive/MyDrive/AI_Projects/STARE/png_data/elastic')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O29E2D--9Ay9"
      },
      "source": [
        "## Flipping"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q2V4mtkc9Dhn"
      },
      "source": [
        "def apply_flipping(input_path, output_path, flip):\n",
        "  '''\n",
        "  - input_path -> folder tree should be like that : input_path-->|\n",
        "                                                                 |-> images\n",
        "                                                                 |-> labels\n",
        "\n",
        "  - output_path -> this is the directory that will store the results\n",
        "\n",
        "  - angels -> this should be a list that includes the angels that you want to rotate images and labels.\n",
        "  '''\n",
        "  PROBLEM = \"semantic_segmentation\"\n",
        "  ANNOTATION_MODE = \"folders\"\n",
        "  INPUT_PATH = input_path + \"/\"\n",
        "  GENERATION_MODE = \"linear\"\n",
        "  OUTPUT_MODE = \"folders\"\n",
        "  OUTPUT_PATH= output_path + \"/\"\n",
        "  LABELS_EXTENSION = \".png\"\n",
        "\n",
        "  augmentor = createAugmentor(PROBLEM,ANNOTATION_MODE,OUTPUT_MODE,GENERATION_MODE,INPUT_PATH,{\"outputPath\":OUTPUT_PATH,\"labelsExtension\":LABELS_EXTENSION})\n",
        "\n",
        "  transformer = transformerGenerator(PROBLEM)\n",
        "\n",
        "  rotate = createTechnique(\"flip\", {\"flip\" : flip})\n",
        "  augmentor.addTransformer(transformer(rotate))\n",
        "\n",
        "  augmentor.applyAugmentation()\n",
        "  print(\"Flipping results were saved given directory.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-7G8AAqg9Dhu"
      },
      "source": [
        "apply_flipping('/content/drive/MyDrive/AI_Projects/STARE/png_data/train',\n",
        "                '/content/drive/MyDrive/AI_Projects/STARE/png_data/flipping1', 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9cOjX19xAgHS"
      },
      "source": [
        "## Shearing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wBM9mlSfAht5"
      },
      "source": [
        "def apply_shearing(input_path, output_path, a = 0.5):\n",
        "  '''\n",
        "  - input_path -> folder tree should be like that : input_path-->|\n",
        "                                                                 |-> images\n",
        "                                                                 |-> labels\n",
        "\n",
        "  - output_path -> this is the directory that will store the results\n",
        "\n",
        "  - angels -> this should be a list that includes the angels that you want to rotate images and labels.\n",
        "  '''\n",
        "  PROBLEM = \"semantic_segmentation\"\n",
        "  ANNOTATION_MODE = \"folders\"\n",
        "  INPUT_PATH = input_path + \"/\"\n",
        "  GENERATION_MODE = \"linear\"\n",
        "  OUTPUT_MODE = \"folders\"\n",
        "  OUTPUT_PATH= output_path + \"/\"\n",
        "  LABELS_EXTENSION = \".png\"\n",
        "\n",
        "  augmentor = createAugmentor(PROBLEM,ANNOTATION_MODE,OUTPUT_MODE,GENERATION_MODE,INPUT_PATH,{\"outputPath\":OUTPUT_PATH,\"labelsExtension\":LABELS_EXTENSION})\n",
        "\n",
        "  transformer = transformerGenerator(PROBLEM)\n",
        "\n",
        "  rotate = createTechnique(\"shearing\", {\"a\" : a})\n",
        "  augmentor.addTransformer(transformer(rotate))\n",
        "\n",
        "  augmentor.applyAugmentation()\n",
        "  print(\"Shearing results were saved given directory.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Hl1vx8ZAht6"
      },
      "source": [
        "apply_shearing('/content/drive/MyDrive/AI_Projects/retina_DRIVE/png_data/train',\n",
        "                '/content/drive/MyDrive/AI_Projects/retina_DRIVE/png_data/shearing',a = 0.3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_lRtntDfCva6"
      },
      "source": [
        "## Sharpen"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OJw_XCZBCvbG"
      },
      "source": [
        "def apply_sharpen(input_path, output_path):\n",
        "  '''\n",
        "  - input_path -> folder tree should be like that : input_path-->|\n",
        "                                                                 |-> images\n",
        "                                                                 |-> labels\n",
        "\n",
        "  - output_path -> this is the directory that will store the results\n",
        "\n",
        "  - angels -> this should be a list that includes the angels that you want to rotate images and labels.\n",
        "  '''\n",
        "  PROBLEM = \"semantic_segmentation\"\n",
        "  ANNOTATION_MODE = \"folders\"\n",
        "  INPUT_PATH = input_path + \"/\"\n",
        "  GENERATION_MODE = \"linear\"\n",
        "  OUTPUT_MODE = \"folders\"\n",
        "  OUTPUT_PATH= output_path + \"/\"\n",
        "  LABELS_EXTENSION = \".png\"\n",
        "\n",
        "  augmentor = createAugmentor(PROBLEM,ANNOTATION_MODE,OUTPUT_MODE,GENERATION_MODE,INPUT_PATH,{\"outputPath\":OUTPUT_PATH,\"labelsExtension\":LABELS_EXTENSION})\n",
        "\n",
        "  transformer = transformerGenerator(PROBLEM)\n",
        "\n",
        "  rotate = createTechnique(\"sharpen\", {})\n",
        "  augmentor.addTransformer(transformer(rotate))\n",
        "\n",
        "  augmentor.applyAugmentation()\n",
        "  print(\"Sharping results were saved given directory.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JR_fijSXCvbH"
      },
      "source": [
        "apply_sharpen('/content/drive/MyDrive/AI_Projects/STARE/png_data/train',\n",
        "                '/content/drive/MyDrive/AI_Projects/STARE/png_data/sharpen')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lSqKh9iBDZOs"
      },
      "source": [
        "## Raise Saturation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tXd_DU1kDyaN"
      },
      "source": [
        "def apply_raise_satur(input_path, output_path, power):\n",
        "  '''\n",
        "  - input_path -> folder tree should be like that : input_path-->|\n",
        "                                                                 |-> images\n",
        "                                                                 |-> labels\n",
        "\n",
        "  - output_path -> this is the directory that will store the results\n",
        "\n",
        "  - angels -> this should be a list that includes the angels that you want to rotate images and labels.\n",
        "  '''\n",
        "  PROBLEM = \"semantic_segmentation\"\n",
        "  ANNOTATION_MODE = \"folders\"\n",
        "  INPUT_PATH = input_path + \"/\"\n",
        "  GENERATION_MODE = \"linear\"\n",
        "  OUTPUT_MODE = \"folders\"\n",
        "  OUTPUT_PATH= output_path + \"/\"\n",
        "  LABELS_EXTENSION = \".png\"\n",
        "\n",
        "  augmentor = createAugmentor(PROBLEM,ANNOTATION_MODE,OUTPUT_MODE,GENERATION_MODE,INPUT_PATH,{\"outputPath\":OUTPUT_PATH,\"labelsExtension\":LABELS_EXTENSION})\n",
        "\n",
        "  transformer = transformerGenerator(PROBLEM)\n",
        "\n",
        "  rotate = createTechnique(\"raise_saturation\", {\"power\" : power})\n",
        "  augmentor.addTransformer(transformer(rotate))\n",
        "\n",
        "  augmentor.applyAugmentation()\n",
        "  print(\"Raise saturation results were saved given directory.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L6_9j3_YDyaO"
      },
      "source": [
        "apply_raise_satur('/content/drive/MyDrive/AI_Projects/retina_DRIVE/png_data/train',\n",
        "                '/content/drive/MyDrive/AI_Projects/retina_DRIVE/png_data/saturation4', 0.5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mmq8dI-AU4Rl"
      },
      "source": [
        "# IMGAUG"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nQ9SXc9yUxJK"
      },
      "source": [
        "## Rotation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yli9R21bn2Xq"
      },
      "source": [
        "input_path = '/content/drive/MyDrive/AI_Projects/STARE/png_data/train'\n",
        "output_path = '/content/drive/MyDrive/AI_Projects/STARE/png_data/deneme8'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J5xP9yvK4BCJ"
      },
      "source": [
        "def rotation(degree, input_path, output_path, image_count):\n",
        "  images = []\n",
        "  labels = []\n",
        "\n",
        "  for img_path in range(image_count):\n",
        "    img = imageio.imread(input_path + '/images/' + str(img_path) + '.png')\n",
        "    images.append(img) \n",
        "\n",
        "    lbl = imageio.imread(input_path + '/labels/' + str(img_path) + '.png')\n",
        "    labels.append(lbl)\n",
        "  \n",
        "  seq = iaa.Sequential(\n",
        "      [\n",
        "\n",
        "          iaa.Rotate((degree)),\n",
        "\n",
        "      ]\n",
        "  )\n",
        "\n",
        "  images_aug = seq(images=images)\n",
        "  labels_aug = seq(images=labels)\n",
        "\n",
        "  path = os.path.join(output_path, 'images') \n",
        "  os.mkdir(path) \n",
        "\n",
        "  path = os.path.join(output_path, 'labels') \n",
        "  os.mkdir(path)\n",
        "\n",
        "  for indx, i in enumerate(images_aug):\n",
        "      imageio.imwrite(output_path + '/images/'  + 'rotat'+ '_' + str(indx) + '.png', i)\n",
        "\n",
        "  for indx, i in enumerate(labels_aug):\n",
        "      imageio.imwrite(output_path + '/labels/'  + 'rotat'+ '_' + str(indx) + '.png', i)\n",
        "\n",
        "  print(\"Rotation results were saved given directory.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W3ABxEFH5hRe"
      },
      "source": [
        "rotation(30,input_path,output_path,20)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dOPUyLqsYTf3"
      },
      "source": [
        "## JPEG Compression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SEM_ogj_g_Iv"
      },
      "source": [
        "import imageio\n",
        "import imgaug as ia\n",
        "import os \n",
        "\n",
        "def apply_jpeg_compression(input_path, output_path, degrees):\n",
        "  '''\n",
        "  - input_path -> folder tree should be like that : input_path-->|\n",
        "                                                                 |-> images\n",
        "                                                                 |-> labels\n",
        "\n",
        "  - output_path -> this is the directory that will store the results\n",
        "\n",
        "  - degrees -> this should be a list that includes the degrees that you want to compress images and labels (must be between 0 and 100).\n",
        "  '''\n",
        "\n",
        "  images = []\n",
        "  labels = []\n",
        "\n",
        "  for img_path in range(20):\n",
        "    img = imageio.imread(input_path + 'images/' + str(img_path) + '.png')\n",
        "    images.append(img) \n",
        "\n",
        "    lbl = imageio.imread(input_path + 'labels/' + str(img_path) + '.png')\n",
        "    labels.append(lbl)\n",
        "  \n",
        "  path = os.path.join(output_path, 'images') \n",
        "  os.mkdir(path) \n",
        "\n",
        "  path = os.path.join(output_path, 'labels') \n",
        "  os.mkdir(path) \n",
        "\n",
        "  for degree in degrees:\n",
        "    aug = ia.augmenters.JpegCompression(compression=degree)\n",
        "    \n",
        "    images_aug = aug.augment_images(images=images)\n",
        "    for indx, i in enumerate(images_aug):\n",
        "      imageio.imwrite(output_path + 'images/' + str(degree) + '_' + str(indx) + '.png', i)\n",
        "\n",
        "    labels_aug = aug.augment_images(images=labels)\n",
        "    for indx, i in enumerate(labels_aug):\n",
        "      imageio.imwrite(output_path + 'labels/' + str(degree) + '_' + str(indx) + '.png', i)\n",
        "\n",
        "  print(\"JPEG Compression results were saved given directory.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t5FFKoori9IY"
      },
      "source": [
        "# 25,50,75 should be in seperate folders\n",
        "\n",
        "apply_jpeg_compression(\"/content/drive/MyDrive/AI_Projects/retina_DRIVE/png_data/train/\",\n",
        "                       \"/content/drive/MyDrive/AI_Projects/retina_DRIVE/png_data/jpeg_compression25/\",\n",
        "                        [25])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AHQDaVx8IN8Q"
      },
      "source": [
        "## Zoom In / Out"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rp5dXKSrrIBv"
      },
      "source": [
        "input_path = '/content/drive/MyDrive/AI_Projects/STARE/png_data/train'\n",
        "output_path = '/content/drive/MyDrive/AI_Projects/STARE/png_data/deneme7'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VHB97Nr31O1h"
      },
      "source": [
        "def zoom(zoom_amount, input_path, output_path, image_count):\n",
        "  images = []\n",
        "  labels = []\n",
        "  ia.seed(1)\n",
        "  for img_path in range(image_count):\n",
        "    img = imageio.imread(input_path + '/images/' + str(img_path) + '.png')\n",
        "    images.append(img) \n",
        "\n",
        "    lbl = imageio.imread(input_path + '/labels/' + str(img_path) + '.png')\n",
        "    labels.append(lbl)\n",
        "  \n",
        "  seq = iaa.Sequential(\n",
        "      [\n",
        "\n",
        "          iaa.Affine(\n",
        "              scale={\"x\": (zoom_amount), \"y\": (zoom_amount)}\n",
        "          ),\n",
        "\n",
        "      ]\n",
        "  )\n",
        "\n",
        "  images_aug = seq(images=images)\n",
        "  labels_aug = seq(images=labels)\n",
        "\n",
        "  path = os.path.join(output_path, 'images') \n",
        "  os.mkdir(path) \n",
        "\n",
        "  path = os.path.join(output_path, 'labels') \n",
        "  os.mkdir(path)\n",
        "\n",
        "  for indx, i in enumerate(images_aug):\n",
        "      imageio.imwrite(output_path + '/images/'  + 'zoom'+ '_' + str(indx) + '.png', i)\n",
        "\n",
        "  for indx, i in enumerate(labels_aug):\n",
        "      imageio.imwrite(output_path + '/labels/'  + 'zoom'+ '_' + str(indx) + '.png', i)\n",
        "\n",
        "  print(\"Zoom results were saved given directory.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iDr_29r91yyM"
      },
      "source": [
        "zoom(0.8, input_path, output_path, 20)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5m-UwYoNqaaD"
      },
      "source": [
        "## Shear X/Y"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TEDi-ZGZqjt_"
      },
      "source": [
        "input_path = '/content/drive/MyDrive/AI_Projects/STARE/png_data/train'\n",
        "output_path = '/content/drive/MyDrive/AI_Projects/STARE/png_data/deneme6'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MyQfU8oMzMRM"
      },
      "source": [
        "def shearX(shear_amount, input_path, output_path, image_count):\n",
        "  images = []\n",
        "  labels = []\n",
        "  ia.seed(1)\n",
        "  for img_path in range(image_count):\n",
        "    img = imageio.imread(input_path + '/images/' + str(img_path) + '.png')\n",
        "    images.append(img) \n",
        "\n",
        "    lbl = imageio.imread(input_path + '/labels/' + str(img_path) + '.png')\n",
        "    labels.append(lbl)\n",
        "  \n",
        "  seq = iaa.Sequential(\n",
        "      [\n",
        "\n",
        "          iaa.ShearX((shear_amount)),\n",
        "\n",
        "      ]\n",
        "  )\n",
        "\n",
        "  images_aug = seq(images=images)\n",
        "  labels_aug = seq(images=labels)\n",
        "\n",
        "  path = os.path.join(output_path, 'images') \n",
        "  os.mkdir(path) \n",
        "\n",
        "  path = os.path.join(output_path, 'labels') \n",
        "  os.mkdir(path)\n",
        "\n",
        "  for indx, i in enumerate(images_aug):\n",
        "      imageio.imwrite(output_path + '/images/'  + 'shear'+ '_' + str(indx) + '.png', i)\n",
        "\n",
        "  for indx, i in enumerate(labels_aug):\n",
        "      imageio.imwrite(output_path + '/labels/'  + 'shear'+ '_' + str(indx) + '.png', i)\n",
        "\n",
        "  print(\"Shear results were saved given directory.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kG4sWByK0m7_"
      },
      "source": [
        "def shearY(shear_amount, input_path, output_path, image_count):\n",
        "  images = []\n",
        "  labels = []\n",
        "  ia.seed(1)\n",
        "  for img_path in range(image_count):\n",
        "    img = imageio.imread(input_path + '/images/' + str(img_path) + '.png')\n",
        "    images.append(img) \n",
        "\n",
        "    lbl = imageio.imread(input_path + '/labels/' + str(img_path) + '.png')\n",
        "    labels.append(lbl)\n",
        "  \n",
        "  seq = iaa.Sequential(\n",
        "      [\n",
        "\n",
        "          iaa.ShearY((shear_amount)),\n",
        "\n",
        "      ]\n",
        "  )\n",
        "\n",
        "  images_aug = seq(images=images)\n",
        "  labels_aug = seq(images=labels)\n",
        "\n",
        "  path = os.path.join(output_path, 'images') \n",
        "  os.mkdir(path) \n",
        "\n",
        "  path = os.path.join(output_path, 'labels') \n",
        "  os.mkdir(path)\n",
        "\n",
        "  for indx, i in enumerate(images_aug):\n",
        "      imageio.imwrite(output_path + '/images/'  + 'shear'+ '_' + str(indx) + '.png', i)\n",
        "\n",
        "  for indx, i in enumerate(labels_aug):\n",
        "      imageio.imwrite(output_path + '/labels/'  + 'shear'+ '_' + str(indx) + '.png', i)\n",
        "\n",
        "  print(\"Shear results were saved given directory.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gJmS_j1XzuRk"
      },
      "source": [
        "shearX(20, input_path, output_path, 20)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jB_RNkULuy0p"
      },
      "source": [
        "## Contrast"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kvrlQ7SfxA0Y"
      },
      "source": [
        "%%capture\n",
        "!pip install imagecorruptions"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "25Af7RFbu7fJ"
      },
      "source": [
        "input_path = '/content/drive/MyDrive/AI_Projects/STARE/png_data/train'\n",
        "output_path = '/content/drive/MyDrive/AI_Projects/STARE/png_data/deneme5'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "svEwk8yXwUbU"
      },
      "source": [
        "def contrast(severity, input_path, output_path, image_count):\n",
        "  images = []\n",
        "  labels = []\n",
        "\n",
        "  for img_path in range(image_count):\n",
        "    img = imageio.imread(input_path + '/images/' + str(img_path) + '.png')\n",
        "    images.append(img) \n",
        "\n",
        "    lbl = imageio.imread(input_path + '/labels/' + str(img_path) + '.png')\n",
        "    labels.append(lbl)\n",
        "  \n",
        "  seq = iaa.Sequential(\n",
        "    [\n",
        "\n",
        "        iaa.imgcorruptlike.Contrast(severity=severity),\n",
        "\n",
        "    ]\n",
        "  )\n",
        "\n",
        "  images_aug = seq(images=images)\n",
        "\n",
        "  path = os.path.join(output_path, 'images') \n",
        "  os.mkdir(path) \n",
        "\n",
        "  path = os.path.join(output_path, 'labels') \n",
        "  os.mkdir(path)\n",
        "\n",
        "  for indx, i in enumerate(images_aug):\n",
        "      imageio.imwrite(output_path + '/images/'  + 'contrast'+ '_' + str(indx) + '.png', i)\n",
        "\n",
        "  for indx, i in enumerate(labels):\n",
        "      imageio.imwrite(output_path + '/labels/'  + 'contrast'+ '_' + str(indx) + '.png', i)\n",
        "\n",
        "  print(\"Contrast results were saved given directory.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KvEtg4s1yJYY"
      },
      "source": [
        "contrast(2,input_path, output_path, image_count= 20)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YkEKHpWi6GDz"
      },
      "source": [
        "\n",
        "## Shift X Y"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IOFEGoks6K9C"
      },
      "source": [
        "import numpy as np\n",
        "import imgaug as ia\n",
        "import imgaug.augmenters as iaa\n",
        "import imageio\n",
        "import os\n",
        "\n",
        "input_path = '/content/drive/MyDrive/AI_Projects/STARE/png_data/train/'\n",
        "output_path = '/content/drive/MyDrive/AI_Projects/STARE/png_data/aug/'\n",
        "\n",
        "shift_amount = -100 #pixel\n",
        "image_count  = 20"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PcRw8B-HtP2Q"
      },
      "source": [
        "def shiftX(shift_amount, input_path, output_path, image_count):\n",
        "  images = []\n",
        "  labels = []\n",
        "\n",
        "  for img_path in range(image_count):\n",
        "    img = imageio.imread(input_path + 'images/' + str(img_path) + '.png')\n",
        "    images.append(img) \n",
        "\n",
        "    lbl = imageio.imread(input_path + 'labels/' + str(img_path) + '.png')\n",
        "    labels.append(lbl)\n",
        "  \n",
        "  seq = iaa.Sequential(\n",
        "    [\n",
        "\n",
        "        iaa.TranslateX(px=(shift_amount))\n",
        "\n",
        "    ]\n",
        "  )\n",
        "\n",
        "  images_aug = seq(images=images)\n",
        "  labels_aug = seq(images=labels)\n",
        "\n",
        "  path = os.path.join(output_path, 'images') \n",
        "  os.mkdir(path) \n",
        "\n",
        "  path = os.path.join(output_path, 'labels') \n",
        "  os.mkdir(path)\n",
        "\n",
        "  for indx, i in enumerate(images_aug):\n",
        "      imageio.imwrite(output_path + 'images/'  + 'shifted'+ '_' + str(indx) + '.png', i)\n",
        "\n",
        "  for indx, i in enumerate(labels_aug):\n",
        "      imageio.imwrite(output_path + 'labels/'  + 'shifted'+ '_' + str(indx) + '.png', i)\n",
        "\n",
        "  print(\"Shift results were saved given directory.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t-MMz3n0usgD"
      },
      "source": [
        "def shiftY(shift_amount, input_path, output_path, image_count):\n",
        "  images = []\n",
        "  labels = []\n",
        "\n",
        "  for img_path in range(image_count):\n",
        "    img = imageio.imread(input_path + 'images/' + str(img_path) + '.png')\n",
        "    images.append(img) \n",
        "\n",
        "    lbl = imageio.imread(input_path + 'labels/' + str(img_path) + '.png')\n",
        "    labels.append(lbl)\n",
        "  \n",
        "  seq = iaa.Sequential(\n",
        "    [\n",
        "\n",
        "        iaa.TranslateY(px=(shift_amount))\n",
        "\n",
        "    ]\n",
        "  )\n",
        "\n",
        "  images_aug = seq(images=images)\n",
        "  labels_aug = seq(images=labels)\n",
        "\n",
        "  path = os.path.join(output_path, 'images') \n",
        "  os.mkdir(path) \n",
        "\n",
        "  path = os.path.join(output_path, 'labels') \n",
        "  os.mkdir(path)\n",
        "\n",
        "  for indx, i in enumerate(images_aug):\n",
        "      imageio.imwrite(output_path + 'images/'  + 'shifted'+ '_' + str(indx) + '.png', i)\n",
        "\n",
        "  for indx, i in enumerate(labels_aug):\n",
        "      imageio.imwrite(output_path + 'labels/'  + 'shifted'+ '_' + str(indx) + '.png', i)\n",
        "\n",
        "  print(\"Shift results were saved given directory.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CdeFsHYkt8Pc"
      },
      "source": [
        "shiftX(shift_amount, input_path, output_path, image_count)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IN1t79D9efeQ"
      },
      "source": [
        "# Albumentations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cXaTVzqIfBwn"
      },
      "source": [
        "\n",
        "\n",
        "1.   Create your main folder in your path\n",
        "2.   Change the paths inside the code properly\n",
        "3.   Choose the method from [here](https://albumentations.ai/docs/examples/example_kaggle_salt/)\n",
        "4.   Change the part between hashtags (####) with this method\n",
        "5.   Output will be in your main path\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OPSJxY8welgC"
      },
      "source": [
        "import os\n",
        "import cv2\n",
        "\n",
        "output_folder_name = 'deneme'\n",
        "\n",
        "main_path = '/content/drive/MyDrive/AI_Projects/STARE/png_data'\n",
        "input_path = '/content/drive/MyDrive/AI_Projects/STARE/png_data/train'\n",
        "\n",
        "original_height, original_width = 608, 704"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oZTuJM8X5Ka1"
      },
      "source": [
        "print(original_height)\n",
        "print(original_width)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-UdinDWbev_j"
      },
      "source": [
        "def albumentation(output_folder_name, main_path, original_height, original_width, input_path):\n",
        "\n",
        "  '''\n",
        "    - output_folder_name : you should give just the name of the output folder, it will be created by function\n",
        "    - main_path : the folder that output folder will be created and results will be saved\n",
        "    - input_path : the folder that includes images and labels in seperate folders\n",
        "  '''\n",
        "\n",
        "  os.mkdir(main_path + '/'+ output_folder_name)\n",
        "  os.mkdir(main_path + '/'+ output_folder_name +'/images')\n",
        "  os.mkdir(main_path + '/'+ output_folder_name +'/labels')\n",
        "\n",
        "  for img in sorted(os.listdir(input_path + '/images')):\n",
        "\n",
        "    image = cv2.imread(input_path +'/images/' + img, 0)\n",
        "    mask  = cv2.imread(input_path +'/labels/' + img, 0)\n",
        "    \n",
        "    ##############################################################\n",
        "    aug = A.Compose([\n",
        "      A.OneOf([\n",
        "          A.RandomSizedCrop(min_max_height=(50, 101), height=original_height, width=original_width, p=0.5),\n",
        "          A.PadIfNeeded(min_height=original_height, min_width=original_width, p=0.5)\n",
        "      ], p=1),    \n",
        "      A.VerticalFlip(p=0.5),              \n",
        "      A.RandomRotate90(p=0.5),\n",
        "      A.OneOf([\n",
        "          A.ElasticTransform(alpha=120, sigma=120 * 0.05, alpha_affine=120 * 0.03, p=0.5),\n",
        "          A.GridDistortion(p=0.5),\n",
        "          A.OpticalDistortion(distort_limit=2, shift_limit=0.5, p=1)                  \n",
        "          ], p=0.8),\n",
        "      A.CLAHE(p=0.8),\n",
        "      A.RandomBrightnessContrast(p=0.8),    \n",
        "      A.RandomGamma(p=0.8)])\n",
        "    ##############################################################\n",
        "\n",
        "    augmented = aug(image=image, mask=mask)\n",
        "\n",
        "    image = augmented['image']\n",
        "    mask = augmented['mask']\n",
        "\n",
        "    cv2.imwrite(main_path +'/'+ output_folder_name +'/images/' + img, image)\n",
        "    cv2.imwrite(main_path +'/' + output_folder_name +'/labels/' + img, mask)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XG_Ky63SquuO"
      },
      "source": [
        "albumentation(output_folder_name, main_path, original_height, original_width, input_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m5RsfiOHRCj_"
      },
      "source": [
        "# Append One Directory to Another"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q79ylsv7fiDW"
      },
      "source": [
        "import os, shutil\n",
        "\n",
        "def merge_augmentations(augment_dir, output_dir, list_of_aug_files):\n",
        "  '''\n",
        "    - augment_dir         (string)   : The path which has subfolders that are augmentation folders.\n",
        "    - output_dir          (string)   : The path you want to put all augmentations.\n",
        "    - list_of_aug_files   (list)     : List of names which contains augmentations.\n",
        "  '''\n",
        "  \n",
        "  os.mkdir(output_dir + '/images')\n",
        "  os.mkdir(output_dir + '/labels')\n",
        "  \n",
        "\n",
        "  for folder in list_of_aug_files:\n",
        "    if folder != 'train':\n",
        "      for file in sorted(os.listdir(augment_dir + '/' + folder + '/images')):\n",
        "        shutil.copy(augment_dir + '/' + folder + '/images/' + file, output_dir + '/images/' + folder + '_' + file.split(\"_\")[-1].split('.')[0] + '.png')\n",
        "        shutil.copy(augment_dir + '/' + folder + '/labels/' + file, output_dir + '/labels/' + folder + '_' + file.split(\"_\")[-1].split('.')[0] + '.png')\n",
        "        #shutil.copy(augment_dir + '/' + folder + '/images/' + file, output_dir + '/images/' + file)\n",
        "        #shutil.copy(augment_dir + '/' + folder + '/labels/' + file, output_dir + '/labels/' + file)\n",
        "    else:\n",
        "      for file in sorted(os.listdir(augment_dir + '/' + folder + '/images')):\n",
        "        shutil.copy(augment_dir + '/' + folder + '/images/' + file, output_dir + '/images/' + file.split(\"_\")[-1].split('.')[0] + '.png')\n",
        "        shutil.copy(augment_dir + '/' + folder + '/labels/' + file, output_dir + '/labels/' + file.split(\"_\")[-1].split('.')[0] + '.png')\n",
        "        #shutil.copy(augment_dir + '/' + folder + '/images/' + file, output_dir + '/images/' + file)\n",
        "        #shutil.copy(augment_dir + '/' + folder + '/labels/' + file, output_dir + '/labels/' + file)\n",
        "\n",
        "    print(folder + ' folder has been merged...')\n",
        "    print('Number of images in output: ' + str(len(os.listdir(output_dir + '/images'))))\n",
        "  \n",
        "  print('Merging is done successfully!')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MMdQtVZ_lpzF"
      },
      "source": [
        "merge_augmentations('/content/drive/MyDrive/AI_Projects/STARE/png_data',\n",
        "                    '/content/drive/MyDrive/AI_Projects/STARE/combinations_png/B', \n",
        "                    ['train', \n",
        "                     'flipping0', \n",
        "                     'flipping1']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1dEs6Xd4r4Bs"
      },
      "source": [
        "# Experimental Style Transfer Part"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rP8njHS4bWvt",
        "outputId": "038b2dbb-c954-4e74-d553-a5f768073db1"
      },
      "source": [
        "%tensorflow_version 1.x"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cnTHPqOo0DNP"
      },
      "source": [
        "!pip install -q 'scipy<=1.2.1'  # scipy.misc.imread is deprecated in later versions"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LDS4ELQ-0R8M",
        "outputId": "4838c800-271c-4b01-c79a-17d362e54183"
      },
      "source": [
        "!git clone https://github.com/titu1994/Neural-Style-Transfer.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'Neural-Style-Transfer'...\n",
            "remote: Enumerating objects: 7, done.\u001b[K\n",
            "remote: Counting objects: 100% (7/7), done.\u001b[K\n",
            "remote: Compressing objects: 100% (7/7), done.\u001b[K\n",
            "remote: Total 1400 (delta 1), reused 3 (delta 0), pack-reused 1393\u001b[K\n",
            "Receiving objects: 100% (1400/1400), 68.16 MiB | 41.74 MiB/s, done.\n",
            "Resolving deltas: 100% (820/820), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xWpC6lGw0V30",
        "outputId": "3484e4f7-518c-49f1-d189-264182e081b6"
      },
      "source": [
        "cd Neural-Style-Transfer/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/Neural-Style-Transfer\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bx5Q7rrIVy6f"
      },
      "source": [
        "LABEL_PATH   = \"/content/drive/MyDrive/AI_Projects/retina_DRIVE/png_data/train/labels\"\n",
        "IMG_PATH     = \"/content/drive/MyDrive/AI_Projects/retina_DRIVE/png_data/train/images\"\n",
        "RESULT_PATH  = \"/content/drive/MyDrive/AI_Projects/retina_DRIVE/png_data/style_transfer\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-zP5ab0m7-vS"
      },
      "source": [
        "import numpy as np\n",
        "import os\n",
        "from skimage.metrics import structural_similarity\n",
        "import cv2\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3jtFoVOG7-s-"
      },
      "source": [
        "def find_distances():\n",
        "  distances = np.zeros((20,20),dtype=float)\n",
        "  for i in sorted(os.listdir(IMG_PATH)):\n",
        "    for j in sorted(os.listdir(IMG_PATH)):\n",
        "      a = cv2.imread(IMG_PATH + '/' + i, 0)\n",
        "      b = cv2.imread(IMG_PATH + '/' + j, 0)\n",
        "\n",
        "      score, diff = structural_similarity(a, b, full=True)\n",
        "      distances[int(i.split('.')[0])][int(j.split('.')[0])] = float(score)\n",
        "\n",
        "  return distances"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DJ4fj9K09T3M"
      },
      "source": [
        "def style_transfer(n_of_iter = 10, content_weight = 0.025, style_weight = 1):\n",
        "  distances = np.zeros((20,20))\n",
        "  distances = find_distances()\n",
        "\n",
        "  result_img = RESULT_PATH + '/images'\n",
        "  result_label = RESULT_PATH + '/labels'\n",
        "\n",
        "  os.mkdir(result_img)\n",
        "  os.mkdir(result_label)\n",
        "\n",
        "  for i in sorted(os.listdir(IMG_PATH)):\n",
        "    furthest = distances[int(i.split('.')[0])].argmin()\n",
        "    furthest_value = distances[int(i.split('.')[0])].min()\n",
        "    os.system('python INetwork.py \"'+ IMG_PATH + '/' + i +'\" \"'+ IMG_PATH + '/' + str(furthest) + '.png' +'\" \"'+ result_img + '/'+ i.split('.')[0] + '\" --image_size 584 --num_iter '+ str(n_of_iter) +' --pool_type \"max\" --model \"vgg19\" --content_weight '+ str(content_weight) +' --style_weight ' + str(style_weight))\n",
        "    os.rename(result_img + '/' + i.split('.')[0] + '_style.png', result_img + '/style_' + i.split('.')[0] + '.png')\n",
        "    \n",
        "    a = cv2.imread(IMG_PATH + '/' + i, 0)\n",
        "    b = cv2.imread(result_img + '/style_' + i , 0)\n",
        "    score, diff = structural_similarity(a, b, full=True)\n",
        "    print(\"style_\" + i + \" saved successfully.\\nFurthest image from \" + i + \" is \" + str(furthest) + \" with similarity: \" + str(furthest_value) + \"\\nSimilarity between \" + i + \" and styled one is: \" + str(score) + \"\\n---------------------------------------------------------------------\") \n",
        "\n",
        "  os.system(\"rsync -a \"+ LABEL_PATH + \"/ \" + result_label)\n",
        "  for i in sorted(os.listdir(result_label)):\n",
        "    os.rename(result_label + '/' + i, result_label + '/style_' + i.split('.')[0] + '.png')\n",
        "  print('Label folder successfully copied from LABEL_PATH.')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eKhdVcCSr9Hm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "470309ed-f7c5-4ed3-cd49-394e8c937848"
      },
      "source": [
        "style_transfer(n_of_iter = 10, content_weight = 0.025, style_weight = 1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "style_0.png saved successfully.\n",
            "Furthest image from 0.png is 13 with similarity: 0.6581827873570326\n",
            "Similarity between 0.png and styled one is: 0.916427185561389\n",
            "---------------------------------------------------------------------\n",
            "style_1.png saved successfully.\n",
            "Furthest image from 1.png is 13 with similarity: 0.6545721609734262\n",
            "Similarity between 1.png and styled one is: 0.9423020593559593\n",
            "---------------------------------------------------------------------\n",
            "style_10.png saved successfully.\n",
            "Furthest image from 10.png is 13 with similarity: 0.6619912221219528\n",
            "Similarity between 10.png and styled one is: 0.9374854737404626\n",
            "---------------------------------------------------------------------\n",
            "style_11.png saved successfully.\n",
            "Furthest image from 11.png is 13 with similarity: 0.6916511963871375\n",
            "Similarity between 11.png and styled one is: 0.9240754506464935\n",
            "---------------------------------------------------------------------\n",
            "style_12.png saved successfully.\n",
            "Furthest image from 12.png is 13 with similarity: 0.6338797967488901\n",
            "Similarity between 12.png and styled one is: 0.9141204549069615\n",
            "---------------------------------------------------------------------\n",
            "style_13.png saved successfully.\n",
            "Furthest image from 13.png is 7 with similarity: 0.624444554107799\n",
            "Similarity between 13.png and styled one is: 0.9583120523693983\n",
            "---------------------------------------------------------------------\n",
            "style_14.png saved successfully.\n",
            "Furthest image from 14.png is 7 with similarity: 0.6805183818610163\n",
            "Similarity between 14.png and styled one is: 0.9805213558039678\n",
            "---------------------------------------------------------------------\n",
            "style_15.png saved successfully.\n",
            "Furthest image from 15.png is 13 with similarity: 0.666134240040633\n",
            "Similarity between 15.png and styled one is: 0.9663060672267942\n",
            "---------------------------------------------------------------------\n",
            "style_16.png saved successfully.\n",
            "Furthest image from 16.png is 2 with similarity: 0.6790913868102619\n",
            "Similarity between 16.png and styled one is: 0.9557142463168761\n",
            "---------------------------------------------------------------------\n",
            "style_17.png saved successfully.\n",
            "Furthest image from 17.png is 13 with similarity: 0.6385782345629184\n",
            "Similarity between 17.png and styled one is: 0.9190484542479569\n",
            "---------------------------------------------------------------------\n",
            "style_18.png saved successfully.\n",
            "Furthest image from 18.png is 13 with similarity: 0.6712383287858426\n",
            "Similarity between 18.png and styled one is: 0.9474391361970734\n",
            "---------------------------------------------------------------------\n",
            "style_19.png saved successfully.\n",
            "Furthest image from 19.png is 13 with similarity: 0.6733169819898165\n",
            "Similarity between 19.png and styled one is: 0.95581547076174\n",
            "---------------------------------------------------------------------\n",
            "style_2.png saved successfully.\n",
            "Furthest image from 2.png is 13 with similarity: 0.631272105491605\n",
            "Similarity between 2.png and styled one is: 0.9277425172637959\n",
            "---------------------------------------------------------------------\n",
            "style_3.png saved successfully.\n",
            "Furthest image from 3.png is 13 with similarity: 0.6608479765838711\n",
            "Similarity between 3.png and styled one is: 0.9098358361276108\n",
            "---------------------------------------------------------------------\n",
            "style_4.png saved successfully.\n",
            "Furthest image from 4.png is 13 with similarity: 0.6918866010243693\n",
            "Similarity between 4.png and styled one is: 0.9438943953600281\n",
            "---------------------------------------------------------------------\n",
            "style_5.png saved successfully.\n",
            "Furthest image from 5.png is 7 with similarity: 0.6700406071202143\n",
            "Similarity between 5.png and styled one is: 0.94622153243222\n",
            "---------------------------------------------------------------------\n",
            "style_6.png saved successfully.\n",
            "Furthest image from 6.png is 13 with similarity: 0.6799699271706624\n",
            "Similarity between 6.png and styled one is: 0.927807455739216\n",
            "---------------------------------------------------------------------\n",
            "style_7.png saved successfully.\n",
            "Furthest image from 7.png is 13 with similarity: 0.624444554107799\n",
            "Similarity between 7.png and styled one is: 0.9404183639875214\n",
            "---------------------------------------------------------------------\n",
            "style_8.png saved successfully.\n",
            "Furthest image from 8.png is 13 with similarity: 0.6802863465171148\n",
            "Similarity between 8.png and styled one is: 0.9642322218954821\n",
            "---------------------------------------------------------------------\n",
            "style_9.png saved successfully.\n",
            "Furthest image from 9.png is 7 with similarity: 0.6752211439943647\n",
            "Similarity between 9.png and styled one is: 0.946276587315474\n",
            "---------------------------------------------------------------------\n",
            "Label folder successfully copied from LABEL_PATH.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tdp5_eg-E0BN"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}