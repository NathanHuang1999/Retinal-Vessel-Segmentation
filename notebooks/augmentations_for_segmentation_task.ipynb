{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "augmentations-for-segmentation-task.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "1dEs6Xd4r4Bs"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V-v9qgSaT1kh"
      },
      "source": [
        "# Mount Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N718mlLeFFcz"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZRSXyN0hT6_5"
      },
      "source": [
        "# Install Libraries and Import"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oYGDWktKFyV8"
      },
      "source": [
        "%%capture\n",
        "!pip install clodsa\n",
        "!pip install -q -U albumentations"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oFBTiz1zvb92"
      },
      "source": [
        "!pip uninstall imgaug"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k3Dz_7HrwsA1"
      },
      "source": [
        "%%capture\n",
        "!pip install git+https://github.com/aleju/imgaug.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yi0-7WwmHOOP"
      },
      "source": [
        "from matplotlib import pyplot as plt\n",
        "from clodsa.augmentors.augmentorFactory import createAugmentor\n",
        "from clodsa.transformers.transformerFactory import transformerGenerator\n",
        "from clodsa.techniques.techniqueFactory import createTechnique\n",
        "import random\n",
        "import cv2\n",
        "import albumentations as A\n",
        "import imageio\n",
        "import imgaug as ia\n",
        "import imgaug.augmenters as iaa\n",
        "import os "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jWIGAkfdUcyz"
      },
      "source": [
        "# CLoDSA"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bXbgFPmUZisv"
      },
      "source": [
        "## Dropout"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mIbahpcnlRp2"
      },
      "source": [
        "def apply_dropout(input_path, output_path, percentages):\n",
        "  '''\n",
        "  - input_path -> folder tree should be like that : input_path-->|\n",
        "                                                                 |-> images\n",
        "                                                                 |-> labels\n",
        "\n",
        "  - output_path -> this is the directory that will store the results\n",
        "\n",
        "  - angels -> this should be a list that includes the angels that you want to rotate images and labels.\n",
        "  '''\n",
        "  PROBLEM = \"semantic_segmentation\"\n",
        "  ANNOTATION_MODE = \"folders\"\n",
        "  INPUT_PATH = input_path + \"/\"\n",
        "  GENERATION_MODE = \"linear\"\n",
        "  OUTPUT_MODE = \"folders\"\n",
        "  OUTPUT_PATH= output_path + \"/\"\n",
        "  LABELS_EXTENSION = \".png\"\n",
        "\n",
        "  augmentor = createAugmentor(PROBLEM,ANNOTATION_MODE,OUTPUT_MODE,GENERATION_MODE,INPUT_PATH,{\"outputPath\":OUTPUT_PATH,\"labelsExtension\":LABELS_EXTENSION})\n",
        "\n",
        "  transformer = transformerGenerator(PROBLEM)\n",
        "\n",
        "  for percentage in percentages:\n",
        "    dropout = createTechnique(\"dropout\", {\"percentage\" : percentage})\n",
        "    augmentor.addTransformer(transformer(dropout))\n",
        "  \n",
        "  augmentor.applyAugmentation()\n",
        "  print(\"Dropout results were saved given directory.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PS1gDvjLldVp"
      },
      "source": [
        "# 0.05, 0,1 should be in seperate folders\n",
        "apply_dropout(\"/content/drive/MyDrive/AI_Projects/STARE/png_data/train\",\n",
        "               \"/content/drive/MyDrive/AI_Projects/STARE/png_data/dropout\",\n",
        "               [0.1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ObSsGPoJnKad"
      },
      "source": [
        "## Gamma Correction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wMuY2zgTGpeq"
      },
      "source": [
        "def apply_gamma_correction(input_path, output_path, gammas):\n",
        "  '''\n",
        "  - input_path -> folder tree should be like that : input_path-->|\n",
        "                                                                 |-> images\n",
        "                                                                 |-> labels\n",
        "\n",
        "  - output_path -> this is the directory that will store the results\n",
        "\n",
        "  - angels -> this should be a list that includes the angels that you want to rotate images and labels.\n",
        "  '''\n",
        "  PROBLEM = \"semantic_segmentation\"\n",
        "  ANNOTATION_MODE = \"folders\"\n",
        "  INPUT_PATH = input_path + \"/\"\n",
        "  GENERATION_MODE = \"linear\"\n",
        "  OUTPUT_MODE = \"folders\"\n",
        "  OUTPUT_PATH= output_path + \"/\"\n",
        "  LABELS_EXTENSION = \".png\"\n",
        "\n",
        "  augmentor = createAugmentor(PROBLEM,ANNOTATION_MODE,OUTPUT_MODE,GENERATION_MODE,INPUT_PATH,{\"outputPath\":OUTPUT_PATH,\"labelsExtension\":LABELS_EXTENSION})\n",
        "\n",
        "  transformer = transformerGenerator(PROBLEM)\n",
        "\n",
        "  for gamma in gammas:\n",
        "    gamma_t = createTechnique(\"gamma\", {\"gamma\" : gamma})\n",
        "    augmentor.addTransformer(transformer(gamma_t))\n",
        "  \n",
        "  augmentor.applyAugmentation()\n",
        "  print(\"Gamma correction results were saved given directory.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kPwHK2trmLKj"
      },
      "source": [
        "#1.5, 2 should be in seperate folders\n",
        "apply_gamma_correction(\"/content/drive/MyDrive/AI_Projects/STARE/png_data/train\",\n",
        "               \"/content/drive/MyDrive/AI_Projects/STARE/png_data/gamma_correction05\",\n",
        "               [0.5])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kPRHORXYnOUS"
      },
      "source": [
        "##Â White Noise"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ysgW42lbnMoL"
      },
      "source": [
        "def apply_white_noise(input_path, output_path, sd):\n",
        "  '''\n",
        "  - input_path -> folder tree should be like that : input_path-->|\n",
        "                                                                 |-> images\n",
        "                                                                 |-> labels\n",
        "\n",
        "  - output_path -> this is the directory that will store the results\n",
        "\n",
        "  - angels -> this should be a list that includes the angels that you want to rotate images and labels.\n",
        "  '''\n",
        "  PROBLEM = \"semantic_segmentation\"\n",
        "  ANNOTATION_MODE = \"folders\"\n",
        "  INPUT_PATH = input_path + \"/\"\n",
        "  GENERATION_MODE = \"linear\"\n",
        "  OUTPUT_MODE = \"folders\"\n",
        "  OUTPUT_PATH= output_path + \"/\"\n",
        "  LABELS_EXTENSION = \".png\"\n",
        "\n",
        "  augmentor = createAugmentor(PROBLEM,ANNOTATION_MODE,OUTPUT_MODE,GENERATION_MODE,INPUT_PATH,{\"outputPath\":OUTPUT_PATH,\"labelsExtension\":LABELS_EXTENSION})\n",
        "\n",
        "  transformer = transformerGenerator(PROBLEM)\n",
        "\n",
        "  for sigma in sd:\n",
        "    white_noise = createTechnique(\"gaussian_noise\", {\"mean\" : 0,\"sigma\":sigma})\n",
        "    augmentor.addTransformer(transformer(white_noise))\n",
        "  \n",
        "  augmentor.applyAugmentation()\n",
        "  print(\"White noise results were saved given directory.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hS23LUg1njup"
      },
      "source": [
        "apply_white_noise(\"/content/drive/MyDrive/AI_Projects/STARE/png_data/train\",\n",
        "               \"/content/drive/MyDrive/AI_Projects/STARE/png_data/white_noise\",\n",
        "               [10])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Rl2UpMTbOZG"
      },
      "source": [
        "## Equalize Histogram"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YdCkpuAVbOZG"
      },
      "source": [
        " def apply_eqhisto(input_path, output_path):\n",
        "  PROBLEM = \"semantic_segmentation\"\n",
        "  ANNOTATION_MODE = \"folders\"\n",
        "  INPUT_PATH = input_path + \"/\"\n",
        "  GENERATION_MODE = \"linear\"\n",
        "  OUTPUT_MODE = \"folders\"\n",
        "  OUTPUT_PATH= output_path + \"/\"\n",
        "  LABELS_EXTENSION = \".png\"\n",
        "\n",
        "  augmentor = createAugmentor(PROBLEM,ANNOTATION_MODE,OUTPUT_MODE,GENERATION_MODE,INPUT_PATH,{\"outputPath\":OUTPUT_PATH,\"labelsExtension\":LABELS_EXTENSION})\n",
        "\n",
        "  transformer = transformerGenerator(PROBLEM)\n",
        "  equalize = createTechnique(\"equalize_histogram\",{})\n",
        "  augmentor.addTransformer(transformer(equalize)) \n",
        "  augmentor.applyAugmentation()\n",
        "\n",
        "  print(\"Equalize histogram results were saved given directory.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NYaFZWwAbOZH"
      },
      "source": [
        "apply_eqhisto(\"/content/drive/MyDrive/AI_Projects/STARE/png_data/train\", \n",
        "              \"/content/drive/MyDrive/AI_Projects/STARE/png_data/eq_hist\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GUNqb-vkbhFp"
      },
      "source": [
        "## Blurring"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bN3xEb3lbhFs"
      },
      "source": [
        "def aug_blurring(input_path, output_path, blurr:list):\n",
        "  PROBLEM = \"semantic_segmentation\"\n",
        "  ANNOTATION_MODE = \"folders\"\n",
        "  INPUT_PATH = input_path + \"/\"\n",
        "  GENERATION_MODE = \"linear\"\n",
        "  OUTPUT_MODE = \"folders\"\n",
        "  OUTPUT_PATH= output_path + \"/\"\n",
        "  LABELS_EXTENSION = \".png\"\n",
        "\n",
        "  augmentor = createAugmentor(PROBLEM,ANNOTATION_MODE,OUTPUT_MODE,GENERATION_MODE,INPUT_PATH,{\"outputPath\":OUTPUT_PATH,\"labelsExtension\":LABELS_EXTENSION})\n",
        "  transformer = transformerGenerator(PROBLEM)\n",
        "\n",
        "  for ker in blurr:\n",
        "    blur = createTechnique(\"blurring\", {\"kernel\" : ker})\n",
        "    augmentor.addTransformer(transformer(blur))\n",
        "    print(\"Blurring for kernel = {} is done\".format(ker))\n",
        "  \n",
        "  augmentor.applyAugmentation()\n",
        "  print(\"Augmentation results were saved given directory.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3SCEH6P2bhFs"
      },
      "source": [
        "#3, 5 should be in seperate folders\n",
        "aug_blurring(\"/content/drive/MyDrive/AI_Projects/STARE/png_data/train\",\n",
        "             \"/content/drive/MyDrive/AI_Projects/STARE/png_data/blurring5\", [5])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nlNVPKGL6q-w"
      },
      "source": [
        "## Elastic Deformation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7yqvJ9ya4zrI"
      },
      "source": [
        "def apply_elastic_deformation(input_path, output_path, alpha = 5, sigma = 0.05):\n",
        "  '''\n",
        "  - input_path -> folder tree should be like that : input_path-->|\n",
        "                                                                 |-> images\n",
        "                                                                 |-> labels\n",
        "\n",
        "  - output_path -> this is the directory that will store the results\n",
        "\n",
        "  - angels -> this should be a list that includes the angels that you want to rotate images and labels.\n",
        "  '''\n",
        "  PROBLEM = \"semantic_segmentation\"\n",
        "  ANNOTATION_MODE = \"folders\"\n",
        "  INPUT_PATH = input_path + \"/\"\n",
        "  GENERATION_MODE = \"linear\"\n",
        "  OUTPUT_MODE = \"folders\"\n",
        "  OUTPUT_PATH= output_path + \"/\"\n",
        "  LABELS_EXTENSION = \".png\"\n",
        "\n",
        "  augmentor = createAugmentor(PROBLEM,ANNOTATION_MODE,OUTPUT_MODE,GENERATION_MODE,INPUT_PATH,{\"outputPath\":OUTPUT_PATH,\"labelsExtension\":LABELS_EXTENSION})\n",
        "\n",
        "  transformer = transformerGenerator(PROBLEM)\n",
        "\n",
        "  rotate = createTechnique(\"elastic\", {\"alpha\" : alpha, \"sigma\" : sigma})\n",
        "  augmentor.addTransformer(transformer(rotate))\n",
        "\n",
        "  augmentor.applyAugmentation()\n",
        "  print(\"Elastic deformation results were saved given directory.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bTl_aNL_5rAN"
      },
      "source": [
        "apply_elastic_deformation('/content/drive/MyDrive/AI_Projects/STARE/png_data/train',\n",
        "                          '/content/drive/MyDrive/AI_Projects/STARE/png_data/elastic')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O29E2D--9Ay9"
      },
      "source": [
        "## Flipping"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q2V4mtkc9Dhn"
      },
      "source": [
        "def apply_flipping(input_path, output_path, flip):\n",
        "  '''\n",
        "  - input_path -> folder tree should be like that : input_path-->|\n",
        "                                                                 |-> images\n",
        "                                                                 |-> labels\n",
        "\n",
        "  - output_path -> this is the directory that will store the results\n",
        "\n",
        "  - angels -> this should be a list that includes the angels that you want to rotate images and labels.\n",
        "  '''\n",
        "  PROBLEM = \"semantic_segmentation\"\n",
        "  ANNOTATION_MODE = \"folders\"\n",
        "  INPUT_PATH = input_path + \"/\"\n",
        "  GENERATION_MODE = \"linear\"\n",
        "  OUTPUT_MODE = \"folders\"\n",
        "  OUTPUT_PATH= output_path + \"/\"\n",
        "  LABELS_EXTENSION = \".png\"\n",
        "\n",
        "  augmentor = createAugmentor(PROBLEM,ANNOTATION_MODE,OUTPUT_MODE,GENERATION_MODE,INPUT_PATH,{\"outputPath\":OUTPUT_PATH,\"labelsExtension\":LABELS_EXTENSION})\n",
        "\n",
        "  transformer = transformerGenerator(PROBLEM)\n",
        "\n",
        "  rotate = createTechnique(\"flip\", {\"flip\" : flip})\n",
        "  augmentor.addTransformer(transformer(rotate))\n",
        "\n",
        "  augmentor.applyAugmentation()\n",
        "  print(\"Flipping results were saved given directory.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-7G8AAqg9Dhu"
      },
      "source": [
        "apply_flipping('/content/drive/MyDrive/AI_Projects/STARE/png_data/train',\n",
        "                '/content/drive/MyDrive/AI_Projects/STARE/png_data/flipping1', 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9cOjX19xAgHS"
      },
      "source": [
        "## Shearing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wBM9mlSfAht5"
      },
      "source": [
        "def apply_shearing(input_path, output_path, a = 0.5):\n",
        "  '''\n",
        "  - input_path -> folder tree should be like that : input_path-->|\n",
        "                                                                 |-> images\n",
        "                                                                 |-> labels\n",
        "\n",
        "  - output_path -> this is the directory that will store the results\n",
        "\n",
        "  - angels -> this should be a list that includes the angels that you want to rotate images and labels.\n",
        "  '''\n",
        "  PROBLEM = \"semantic_segmentation\"\n",
        "  ANNOTATION_MODE = \"folders\"\n",
        "  INPUT_PATH = input_path + \"/\"\n",
        "  GENERATION_MODE = \"linear\"\n",
        "  OUTPUT_MODE = \"folders\"\n",
        "  OUTPUT_PATH= output_path + \"/\"\n",
        "  LABELS_EXTENSION = \".png\"\n",
        "\n",
        "  augmentor = createAugmentor(PROBLEM,ANNOTATION_MODE,OUTPUT_MODE,GENERATION_MODE,INPUT_PATH,{\"outputPath\":OUTPUT_PATH,\"labelsExtension\":LABELS_EXTENSION})\n",
        "\n",
        "  transformer = transformerGenerator(PROBLEM)\n",
        "\n",
        "  rotate = createTechnique(\"shearing\", {\"a\" : a})\n",
        "  augmentor.addTransformer(transformer(rotate))\n",
        "\n",
        "  augmentor.applyAugmentation()\n",
        "  print(\"Shearing results were saved given directory.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Hl1vx8ZAht6"
      },
      "source": [
        "apply_shearing('/content/drive/MyDrive/AI_Projects/retina_DRIVE/png_data/train',\n",
        "                '/content/drive/MyDrive/AI_Projects/retina_DRIVE/png_data/shearing',a = 0.3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_lRtntDfCva6"
      },
      "source": [
        "## Sharpen"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OJw_XCZBCvbG"
      },
      "source": [
        "def apply_sharpen(input_path, output_path):\n",
        "  '''\n",
        "  - input_path -> folder tree should be like that : input_path-->|\n",
        "                                                                 |-> images\n",
        "                                                                 |-> labels\n",
        "\n",
        "  - output_path -> this is the directory that will store the results\n",
        "\n",
        "  - angels -> this should be a list that includes the angels that you want to rotate images and labels.\n",
        "  '''\n",
        "  PROBLEM = \"semantic_segmentation\"\n",
        "  ANNOTATION_MODE = \"folders\"\n",
        "  INPUT_PATH = input_path + \"/\"\n",
        "  GENERATION_MODE = \"linear\"\n",
        "  OUTPUT_MODE = \"folders\"\n",
        "  OUTPUT_PATH= output_path + \"/\"\n",
        "  LABELS_EXTENSION = \".png\"\n",
        "\n",
        "  augmentor = createAugmentor(PROBLEM,ANNOTATION_MODE,OUTPUT_MODE,GENERATION_MODE,INPUT_PATH,{\"outputPath\":OUTPUT_PATH,\"labelsExtension\":LABELS_EXTENSION})\n",
        "\n",
        "  transformer = transformerGenerator(PROBLEM)\n",
        "\n",
        "  rotate = createTechnique(\"sharpen\", {})\n",
        "  augmentor.addTransformer(transformer(rotate))\n",
        "\n",
        "  augmentor.applyAugmentation()\n",
        "  print(\"Sharping results were saved given directory.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JR_fijSXCvbH"
      },
      "source": [
        "apply_sharpen('/content/drive/MyDrive/AI_Projects/STARE/png_data/train',\n",
        "                '/content/drive/MyDrive/AI_Projects/STARE/png_data/sharpen')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lSqKh9iBDZOs"
      },
      "source": [
        "## Raise Saturation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tXd_DU1kDyaN"
      },
      "source": [
        "def apply_raise_satur(input_path, output_path, power):\n",
        "  '''\n",
        "  - input_path -> folder tree should be like that : input_path-->|\n",
        "                                                                 |-> images\n",
        "                                                                 |-> labels\n",
        "\n",
        "  - output_path -> this is the directory that will store the results\n",
        "\n",
        "  - angels -> this should be a list that includes the angels that you want to rotate images and labels.\n",
        "  '''\n",
        "  PROBLEM = \"semantic_segmentation\"\n",
        "  ANNOTATION_MODE = \"folders\"\n",
        "  INPUT_PATH = input_path + \"/\"\n",
        "  GENERATION_MODE = \"linear\"\n",
        "  OUTPUT_MODE = \"folders\"\n",
        "  OUTPUT_PATH= output_path + \"/\"\n",
        "  LABELS_EXTENSION = \".png\"\n",
        "\n",
        "  augmentor = createAugmentor(PROBLEM,ANNOTATION_MODE,OUTPUT_MODE,GENERATION_MODE,INPUT_PATH,{\"outputPath\":OUTPUT_PATH,\"labelsExtension\":LABELS_EXTENSION})\n",
        "\n",
        "  transformer = transformerGenerator(PROBLEM)\n",
        "\n",
        "  rotate = createTechnique(\"raise_saturation\", {\"power\" : power})\n",
        "  augmentor.addTransformer(transformer(rotate))\n",
        "\n",
        "  augmentor.applyAugmentation()\n",
        "  print(\"Raise saturation results were saved given directory.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L6_9j3_YDyaO"
      },
      "source": [
        "apply_raise_satur('/content/drive/MyDrive/AI_Projects/retina_DRIVE/png_data/train',\n",
        "                '/content/drive/MyDrive/AI_Projects/retina_DRIVE/png_data/saturation4', 0.5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mmq8dI-AU4Rl"
      },
      "source": [
        "# IMGAUG"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nQ9SXc9yUxJK"
      },
      "source": [
        "## Rotation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yli9R21bn2Xq"
      },
      "source": [
        "input_path = '/content/drive/MyDrive/AI_Projects/STARE/png_data/train'\n",
        "output_path = '/content/drive/MyDrive/AI_Projects/STARE/png_data/deneme8'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J5xP9yvK4BCJ"
      },
      "source": [
        "def rotation(degree, input_path, output_path, image_count):\n",
        "  images = []\n",
        "  labels = []\n",
        "\n",
        "  for img_path in range(image_count):\n",
        "    img = imageio.imread(input_path + '/images/' + str(img_path) + '.png')\n",
        "    images.append(img) \n",
        "\n",
        "    lbl = imageio.imread(input_path + '/labels/' + str(img_path) + '.png')\n",
        "    labels.append(lbl)\n",
        "  \n",
        "  seq = iaa.Sequential(\n",
        "      [\n",
        "\n",
        "          iaa.Rotate((degree)),\n",
        "\n",
        "      ]\n",
        "  )\n",
        "\n",
        "  images_aug = seq(images=images)\n",
        "  labels_aug = seq(images=labels)\n",
        "\n",
        "  path = os.path.join(output_path, 'images') \n",
        "  os.mkdir(path) \n",
        "\n",
        "  path = os.path.join(output_path, 'labels') \n",
        "  os.mkdir(path)\n",
        "\n",
        "  for indx, i in enumerate(images_aug):\n",
        "      imageio.imwrite(output_path + '/images/'  + 'rotat'+ '_' + str(indx) + '.png', i)\n",
        "\n",
        "  for indx, i in enumerate(labels_aug):\n",
        "      imageio.imwrite(output_path + '/labels/'  + 'rotat'+ '_' + str(indx) + '.png', i)\n",
        "\n",
        "  print(\"Rotation results were saved given directory.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W3ABxEFH5hRe"
      },
      "source": [
        "rotation(30,input_path,output_path,20)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dOPUyLqsYTf3"
      },
      "source": [
        "## JPEG Compression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SEM_ogj_g_Iv"
      },
      "source": [
        "import imageio\n",
        "import imgaug as ia\n",
        "import os \n",
        "\n",
        "def apply_jpeg_compression(input_path, output_path, degrees):\n",
        "  '''\n",
        "  - input_path -> folder tree should be like that : input_path-->|\n",
        "                                                                 |-> images\n",
        "                                                                 |-> labels\n",
        "\n",
        "  - output_path -> this is the directory that will store the results\n",
        "\n",
        "  - degrees -> this should be a list that includes the degrees that you want to compress images and labels (must be between 0 and 100).\n",
        "  '''\n",
        "\n",
        "  images = []\n",
        "  labels = []\n",
        "\n",
        "  for img_path in range(20):\n",
        "    img = imageio.imread(input_path + 'images/' + str(img_path) + '.png')\n",
        "    images.append(img) \n",
        "\n",
        "    lbl = imageio.imread(input_path + 'labels/' + str(img_path) + '.png')\n",
        "    labels.append(lbl)\n",
        "  \n",
        "  path = os.path.join(output_path, 'images') \n",
        "  os.mkdir(path) \n",
        "\n",
        "  path = os.path.join(output_path, 'labels') \n",
        "  os.mkdir(path) \n",
        "\n",
        "  for degree in degrees:\n",
        "    aug = ia.augmenters.JpegCompression(compression=degree)\n",
        "    \n",
        "    images_aug = aug.augment_images(images=images)\n",
        "    for indx, i in enumerate(images_aug):\n",
        "      imageio.imwrite(output_path + 'images/' + str(degree) + '_' + str(indx) + '.png', i)\n",
        "\n",
        "    labels_aug = aug.augment_images(images=labels)\n",
        "    for indx, i in enumerate(labels_aug):\n",
        "      imageio.imwrite(output_path + 'labels/' + str(degree) + '_' + str(indx) + '.png', i)\n",
        "\n",
        "  print(\"JPEG Compression results were saved given directory.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t5FFKoori9IY"
      },
      "source": [
        "# 25,50,75 should be in seperate folders\n",
        "\n",
        "apply_jpeg_compression(\"/content/drive/MyDrive/AI_Projects/retina_DRIVE/png_data/train/\",\n",
        "                       \"/content/drive/MyDrive/AI_Projects/retina_DRIVE/png_data/jpeg_compression25/\",\n",
        "                        [25])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AHQDaVx8IN8Q"
      },
      "source": [
        "## Zoom In / Out"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rp5dXKSrrIBv"
      },
      "source": [
        "input_path = '/content/drive/MyDrive/AI_Projects/STARE/png_data/train'\n",
        "output_path = '/content/drive/MyDrive/AI_Projects/STARE/png_data/deneme7'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VHB97Nr31O1h"
      },
      "source": [
        "def zoom(zoom_amount, input_path, output_path, image_count):\n",
        "  images = []\n",
        "  labels = []\n",
        "  ia.seed(1)\n",
        "  for img_path in range(image_count):\n",
        "    img = imageio.imread(input_path + '/images/' + str(img_path) + '.png')\n",
        "    images.append(img) \n",
        "\n",
        "    lbl = imageio.imread(input_path + '/labels/' + str(img_path) + '.png')\n",
        "    labels.append(lbl)\n",
        "  \n",
        "  seq = iaa.Sequential(\n",
        "      [\n",
        "\n",
        "          iaa.Affine(\n",
        "              scale={\"x\": (zoom_amount), \"y\": (zoom_amount)}\n",
        "          ),\n",
        "\n",
        "      ]\n",
        "  )\n",
        "\n",
        "  images_aug = seq(images=images)\n",
        "  labels_aug = seq(images=labels)\n",
        "\n",
        "  path = os.path.join(output_path, 'images') \n",
        "  os.mkdir(path) \n",
        "\n",
        "  path = os.path.join(output_path, 'labels') \n",
        "  os.mkdir(path)\n",
        "\n",
        "  for indx, i in enumerate(images_aug):\n",
        "      imageio.imwrite(output_path + '/images/'  + 'zoom'+ '_' + str(indx) + '.png', i)\n",
        "\n",
        "  for indx, i in enumerate(labels_aug):\n",
        "      imageio.imwrite(output_path + '/labels/'  + 'zoom'+ '_' + str(indx) + '.png', i)\n",
        "\n",
        "  print(\"Zoom results were saved given directory.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iDr_29r91yyM"
      },
      "source": [
        "zoom(0.8, input_path, output_path, 20)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5m-UwYoNqaaD"
      },
      "source": [
        "## Shear X/Y"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TEDi-ZGZqjt_"
      },
      "source": [
        "input_path = '/content/drive/MyDrive/AI_Projects/STARE/png_data/train'\n",
        "output_path = '/content/drive/MyDrive/AI_Projects/STARE/png_data/deneme6'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MyQfU8oMzMRM"
      },
      "source": [
        "def shearX(shear_amount, input_path, output_path, image_count):\n",
        "  images = []\n",
        "  labels = []\n",
        "  ia.seed(1)\n",
        "  for img_path in range(image_count):\n",
        "    img = imageio.imread(input_path + '/images/' + str(img_path) + '.png')\n",
        "    images.append(img) \n",
        "\n",
        "    lbl = imageio.imread(input_path + '/labels/' + str(img_path) + '.png')\n",
        "    labels.append(lbl)\n",
        "  \n",
        "  seq = iaa.Sequential(\n",
        "      [\n",
        "\n",
        "          iaa.ShearX((shear_amount)),\n",
        "\n",
        "      ]\n",
        "  )\n",
        "\n",
        "  images_aug = seq(images=images)\n",
        "  labels_aug = seq(images=labels)\n",
        "\n",
        "  path = os.path.join(output_path, 'images') \n",
        "  os.mkdir(path) \n",
        "\n",
        "  path = os.path.join(output_path, 'labels') \n",
        "  os.mkdir(path)\n",
        "\n",
        "  for indx, i in enumerate(images_aug):\n",
        "      imageio.imwrite(output_path + '/images/'  + 'shear'+ '_' + str(indx) + '.png', i)\n",
        "\n",
        "  for indx, i in enumerate(labels_aug):\n",
        "      imageio.imwrite(output_path + '/labels/'  + 'shear'+ '_' + str(indx) + '.png', i)\n",
        "\n",
        "  print(\"Shear results were saved given directory.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kG4sWByK0m7_"
      },
      "source": [
        "def shearY(shear_amount, input_path, output_path, image_count):\n",
        "  images = []\n",
        "  labels = []\n",
        "  ia.seed(1)\n",
        "  for img_path in range(image_count):\n",
        "    img = imageio.imread(input_path + '/images/' + str(img_path) + '.png')\n",
        "    images.append(img) \n",
        "\n",
        "    lbl = imageio.imread(input_path + '/labels/' + str(img_path) + '.png')\n",
        "    labels.append(lbl)\n",
        "  \n",
        "  seq = iaa.Sequential(\n",
        "      [\n",
        "\n",
        "          iaa.ShearY((shear_amount)),\n",
        "\n",
        "      ]\n",
        "  )\n",
        "\n",
        "  images_aug = seq(images=images)\n",
        "  labels_aug = seq(images=labels)\n",
        "\n",
        "  path = os.path.join(output_path, 'images') \n",
        "  os.mkdir(path) \n",
        "\n",
        "  path = os.path.join(output_path, 'labels') \n",
        "  os.mkdir(path)\n",
        "\n",
        "  for indx, i in enumerate(images_aug):\n",
        "      imageio.imwrite(output_path + '/images/'  + 'shear'+ '_' + str(indx) + '.png', i)\n",
        "\n",
        "  for indx, i in enumerate(labels_aug):\n",
        "      imageio.imwrite(output_path + '/labels/'  + 'shear'+ '_' + str(indx) + '.png', i)\n",
        "\n",
        "  print(\"Shear results were saved given directory.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gJmS_j1XzuRk"
      },
      "source": [
        "shearX(20, input_path, output_path, 20)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jB_RNkULuy0p"
      },
      "source": [
        "## Contrast"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kvrlQ7SfxA0Y"
      },
      "source": [
        "%%capture\n",
        "!pip install imagecorruptions"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "25Af7RFbu7fJ"
      },
      "source": [
        "input_path = '/content/drive/MyDrive/AI_Projects/STARE/png_data/train'\n",
        "output_path = '/content/drive/MyDrive/AI_Projects/STARE/png_data/deneme5'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "svEwk8yXwUbU"
      },
      "source": [
        "def contrast(severity, input_path, output_path, image_count):\n",
        "  images = []\n",
        "  labels = []\n",
        "\n",
        "  for img_path in range(image_count):\n",
        "    img = imageio.imread(input_path + '/images/' + str(img_path) + '.png')\n",
        "    images.append(img) \n",
        "\n",
        "    lbl = imageio.imread(input_path + '/labels/' + str(img_path) + '.png')\n",
        "    labels.append(lbl)\n",
        "  \n",
        "  seq = iaa.Sequential(\n",
        "    [\n",
        "\n",
        "        iaa.imgcorruptlike.Contrast(severity=severity),\n",
        "\n",
        "    ]\n",
        "  )\n",
        "\n",
        "  images_aug = seq(images=images)\n",
        "\n",
        "  path = os.path.join(output_path, 'images') \n",
        "  os.mkdir(path) \n",
        "\n",
        "  path = os.path.join(output_path, 'labels') \n",
        "  os.mkdir(path)\n",
        "\n",
        "  for indx, i in enumerate(images_aug):\n",
        "      imageio.imwrite(output_path + '/images/'  + 'contrast'+ '_' + str(indx) + '.png', i)\n",
        "\n",
        "  for indx, i in enumerate(labels):\n",
        "      imageio.imwrite(output_path + '/labels/'  + 'contrast'+ '_' + str(indx) + '.png', i)\n",
        "\n",
        "  print(\"Contrast results were saved given directory.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KvEtg4s1yJYY"
      },
      "source": [
        "contrast(2,input_path, output_path, image_count= 20)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YkEKHpWi6GDz"
      },
      "source": [
        "\n",
        "## Shift X Y"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IOFEGoks6K9C"
      },
      "source": [
        "import numpy as np\n",
        "import imgaug as ia\n",
        "import imgaug.augmenters as iaa\n",
        "import imageio\n",
        "import os\n",
        "\n",
        "input_path = '/content/drive/MyDrive/AI_Projects/STARE/png_data/train/'\n",
        "output_path = '/content/drive/MyDrive/AI_Projects/STARE/png_data/aug/'\n",
        "\n",
        "shift_amount = -100 #pixel\n",
        "image_count  = 20"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PcRw8B-HtP2Q"
      },
      "source": [
        "def shiftX(shift_amount, input_path, output_path, image_count):\n",
        "  images = []\n",
        "  labels = []\n",
        "\n",
        "  for img_path in range(image_count):\n",
        "    img = imageio.imread(input_path + 'images/' + str(img_path) + '.png')\n",
        "    images.append(img) \n",
        "\n",
        "    lbl = imageio.imread(input_path + 'labels/' + str(img_path) + '.png')\n",
        "    labels.append(lbl)\n",
        "  \n",
        "  seq = iaa.Sequential(\n",
        "    [\n",
        "\n",
        "        iaa.TranslateX(px=(shift_amount))\n",
        "\n",
        "    ]\n",
        "  )\n",
        "\n",
        "  images_aug = seq(images=images)\n",
        "  labels_aug = seq(images=labels)\n",
        "\n",
        "  path = os.path.join(output_path, 'images') \n",
        "  os.mkdir(path) \n",
        "\n",
        "  path = os.path.join(output_path, 'labels') \n",
        "  os.mkdir(path)\n",
        "\n",
        "  for indx, i in enumerate(images_aug):\n",
        "      imageio.imwrite(output_path + 'images/'  + 'shifted'+ '_' + str(indx) + '.png', i)\n",
        "\n",
        "  for indx, i in enumerate(labels_aug):\n",
        "      imageio.imwrite(output_path + 'labels/'  + 'shifted'+ '_' + str(indx) + '.png', i)\n",
        "\n",
        "  print(\"Shift results were saved given directory.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t-MMz3n0usgD"
      },
      "source": [
        "def shiftY(shift_amount, input_path, output_path, image_count):\n",
        "  images = []\n",
        "  labels = []\n",
        "\n",
        "  for img_path in range(image_count):\n",
        "    img = imageio.imread(input_path + 'images/' + str(img_path) + '.png')\n",
        "    images.append(img) \n",
        "\n",
        "    lbl = imageio.imread(input_path + 'labels/' + str(img_path) + '.png')\n",
        "    labels.append(lbl)\n",
        "  \n",
        "  seq = iaa.Sequential(\n",
        "    [\n",
        "\n",
        "        iaa.TranslateY(px=(shift_amount))\n",
        "\n",
        "    ]\n",
        "  )\n",
        "\n",
        "  images_aug = seq(images=images)\n",
        "  labels_aug = seq(images=labels)\n",
        "\n",
        "  path = os.path.join(output_path, 'images') \n",
        "  os.mkdir(path) \n",
        "\n",
        "  path = os.path.join(output_path, 'labels') \n",
        "  os.mkdir(path)\n",
        "\n",
        "  for indx, i in enumerate(images_aug):\n",
        "      imageio.imwrite(output_path + 'images/'  + 'shifted'+ '_' + str(indx) + '.png', i)\n",
        "\n",
        "  for indx, i in enumerate(labels_aug):\n",
        "      imageio.imwrite(output_path + 'labels/'  + 'shifted'+ '_' + str(indx) + '.png', i)\n",
        "\n",
        "  print(\"Shift results were saved given directory.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CdeFsHYkt8Pc"
      },
      "source": [
        "shiftX(shift_amount, input_path, output_path, image_count)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IN1t79D9efeQ"
      },
      "source": [
        "# Albumentations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cXaTVzqIfBwn"
      },
      "source": [
        "\n",
        "\n",
        "1.   Create your main folder in your path\n",
        "2.   Change the paths inside the code properly\n",
        "3.   Choose the method from [here](https://albumentations.ai/docs/examples/example_kaggle_salt/)\n",
        "4.   Change the part between hashtags (####) with this method\n",
        "5.   Output will be in your main path\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OPSJxY8welgC"
      },
      "source": [
        "import os\n",
        "import cv2\n",
        "\n",
        "output_folder_name = 'deneme'\n",
        "\n",
        "main_path = '/content/drive/MyDrive/AI_Projects/STARE/png_data'\n",
        "input_path = '/content/drive/MyDrive/AI_Projects/STARE/png_data/train'\n",
        "\n",
        "original_height, original_width = 608, 704"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oZTuJM8X5Ka1"
      },
      "source": [
        "print(original_height)\n",
        "print(original_width)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-UdinDWbev_j"
      },
      "source": [
        "def albumentation(output_folder_name, main_path, original_height, original_width, input_path):\n",
        "\n",
        "  '''\n",
        "    - output_folder_name : you should give just the name of the output folder, it will be created by function\n",
        "    - main_path : the folder that output folder will be created and results will be saved\n",
        "    - input_path : the folder that includes images and labels in seperate folders\n",
        "  '''\n",
        "\n",
        "  os.mkdir(main_path + '/'+ output_folder_name)\n",
        "  os.mkdir(main_path + '/'+ output_folder_name +'/images')\n",
        "  os.mkdir(main_path + '/'+ output_folder_name +'/labels')\n",
        "\n",
        "  for img in sorted(os.listdir(input_path + '/images')):\n",
        "\n",
        "    image = cv2.imread(input_path +'/images/' + img, 0)\n",
        "    mask  = cv2.imread(input_path +'/labels/' + img, 0)\n",
        "    \n",
        "    ##############################################################\n",
        "    aug = A.Compose([\n",
        "      A.OneOf([\n",
        "          A.RandomSizedCrop(min_max_height=(50, 101), height=original_height, width=original_width, p=0.5),\n",
        "          A.PadIfNeeded(min_height=original_height, min_width=original_width, p=0.5)\n",
        "      ], p=1),    \n",
        "      A.VerticalFlip(p=0.5),              \n",
        "      A.RandomRotate90(p=0.5),\n",
        "      A.OneOf([\n",
        "          A.ElasticTransform(alpha=120, sigma=120 * 0.05, alpha_affine=120 * 0.03, p=0.5),\n",
        "          A.GridDistortion(p=0.5),\n",
        "          A.OpticalDistortion(distort_limit=2, shift_limit=0.5, p=1)                  \n",
        "          ], p=0.8),\n",
        "      A.CLAHE(p=0.8),\n",
        "      A.RandomBrightnessContrast(p=0.8),    \n",
        "      A.RandomGamma(p=0.8)])\n",
        "    ##############################################################\n",
        "\n",
        "    augmented = aug(image=image, mask=mask)\n",
        "\n",
        "    image = augmented['image']\n",
        "    mask = augmented['mask']\n",
        "\n",
        "    cv2.imwrite(main_path +'/'+ output_folder_name +'/images/' + img, image)\n",
        "    cv2.imwrite(main_path +'/' + output_folder_name +'/labels/' + img, mask)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XG_Ky63SquuO"
      },
      "source": [
        "albumentation(output_folder_name, main_path, original_height, original_width, input_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m5RsfiOHRCj_"
      },
      "source": [
        "# Append One Directory to Another"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q79ylsv7fiDW"
      },
      "source": [
        "import os, shutil\n",
        "\n",
        "def merge_augmentations(augment_dir, output_dir, list_of_aug_files):\n",
        "  '''\n",
        "    - augment_dir         (string)   : The path which has subfolders that are augmentation folders.\n",
        "    - output_dir          (string)   : The path you want to put all augmentations.\n",
        "    - list_of_aug_files   (list)     : List of names which contains augmentations.\n",
        "  '''\n",
        "  \n",
        "  os.mkdir(output_dir + '/images')\n",
        "  os.mkdir(output_dir + '/labels')\n",
        "  \n",
        "\n",
        "  for folder in list_of_aug_files:\n",
        "    if folder != 'train':\n",
        "      for file in sorted(os.listdir(augment_dir + '/' + folder + '/images')):\n",
        "        shutil.copy(augment_dir + '/' + folder + '/images/' + file, output_dir + '/images/' + folder + '_' + file.split(\"_\")[-1].split('.')[0] + '.png')\n",
        "        shutil.copy(augment_dir + '/' + folder + '/labels/' + file, output_dir + '/labels/' + folder + '_' + file.split(\"_\")[-1].split('.')[0] + '.png')\n",
        "        #shutil.copy(augment_dir + '/' + folder + '/images/' + file, output_dir + '/images/' + file)\n",
        "        #shutil.copy(augment_dir + '/' + folder + '/labels/' + file, output_dir + '/labels/' + file)\n",
        "    else:\n",
        "      for file in sorted(os.listdir(augment_dir + '/' + folder + '/images')):\n",
        "        shutil.copy(augment_dir + '/' + folder + '/images/' + file, output_dir + '/images/' + file.split(\"_\")[-1].split('.')[0] + '.png')\n",
        "        shutil.copy(augment_dir + '/' + folder + '/labels/' + file, output_dir + '/labels/' + file.split(\"_\")[-1].split('.')[0] + '.png')\n",
        "        #shutil.copy(augment_dir + '/' + folder + '/images/' + file, output_dir + '/images/' + file)\n",
        "        #shutil.copy(augment_dir + '/' + folder + '/labels/' + file, output_dir + '/labels/' + file)\n",
        "\n",
        "    print(folder + ' folder has been merged...')\n",
        "    print('Number of images in output: ' + str(len(os.listdir(output_dir + '/images'))))\n",
        "  \n",
        "  print('Merging is done successfully!')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MMdQtVZ_lpzF",
        "outputId": "1ba09548-1abc-44c7-cfaf-f873c33cf73c"
      },
      "source": [
        "merge_augmentations('/content/drive/MyDrive/AI_Projects/STARE/png_data',\n",
        "                    '/content/drive/MyDrive/AI_Projects/STARE/combinations_png/B', \n",
        "                    ['train', \n",
        "                     'flipping0', \n",
        "                     'flipping1', \n",
        "                     'rotat30', \n",
        "                     'rotat60', \n",
        "                     'rotat90', \n",
        "                     'rotat120', \n",
        "                     'rotat150', \n",
        "                     'rotat180', \n",
        "                     'rotat210', \n",
        "                     'rotat240', \n",
        "                     'rotat270', \n",
        "                     'rotat300', \n",
        "                     'rotat330', \n",
        "                     'flipping0_30','flipping0_60',\n",
        "                     'flipping0_90','flipping0_120',\n",
        "                     'flipping0_150',\n",
        "                     'flipping0_180',\n",
        "                     'flipping0_210','flipping0_240',\n",
        "                     'flipping0_270',\n",
        "                     'flipping0_300','flipping0_330',\n",
        "                     'flipping1_30','flipping1_60',\n",
        "                     'flipping1_90','flipping1_120',\n",
        "                     'flipping1_150',\n",
        "                     'flipping1_180',\n",
        "                     'flipping1_210','flipping1_240',\n",
        "                     'flipping1_270',\n",
        "                     'flipping1_300','flipping1_330',\n",
        "                     'zoom_out08',\n",
        "                     'zoom_out08_30', 'zoom_out08_60',\n",
        "                     'zoom_out08_90',\n",
        "                     'zoom_out08_120',\n",
        "                     'zoom_out08_180','zoom_out08_150',\n",
        "                     'zoom_out08_210','zoom_out08_240',\n",
        "                     'zoom_out08_270',\n",
        "                     'zoom_out08_300',\n",
        "                     'zoom_out08_330',\n",
        "                     'white_noise','white_noise90','white_noise180','white_noise270',\n",
        "                     'elastic',\n",
        "                     'shifty_100','shifty_-100','shiftx_100','shiftx_-100',\n",
        "                     'shifty_100_90','shifty_100_180','shifty_100_270',\n",
        "                     'shifty_-100_90','shifty_-100_180','shifty_-100_270',\n",
        "                     'shiftx_100_90','shiftx_100_180','shiftx_100_270',\n",
        "                     'shiftx_-100_90','shiftx_-100_180','shiftx_-100_270',\n",
        "                     'gamma_correction05','gamma_correction05_30','gamma_correction05_60',\n",
        "                     'gamma_correction05_90','gamma_correction05_120','gamma_correction05_150',\n",
        "                     'gamma_correction05_180','gamma_correction05_210','gamma_correction05_240',\n",
        "                     'gamma_correction05_270','gamma_correction05_300','gamma_correction05_330',\n",
        "                     'album_grid_dist','album_heavy', 'album_medium', 'album_optical','album_random_crop',\n",
        "                     'album_grid_dist90','album_grid_dist180','album_grid_dist270',\n",
        "                     'album_heavy90','album_heavy180','album_heavy270','album_medium90','album_medium180','album_medium270',\n",
        "                     'album_optical90', 'album_optical180', 'album_optical270','album_random_crop2','album_random_crop3','album_random_crop4',\n",
        "                     'blurring3', 'blurring5','dropout','eq_hist', 'sharpen'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train folder has been merged...\n",
            "Number of images in output: 20\n",
            "flipping0 folder has been merged...\n",
            "Number of images in output: 40\n",
            "flipping1 folder has been merged...\n",
            "Number of images in output: 60\n",
            "rotat30 folder has been merged...\n",
            "Number of images in output: 80\n",
            "rotat60 folder has been merged...\n",
            "Number of images in output: 100\n",
            "rotat90 folder has been merged...\n",
            "Number of images in output: 120\n",
            "rotat120 folder has been merged...\n",
            "Number of images in output: 140\n",
            "rotat150 folder has been merged...\n",
            "Number of images in output: 160\n",
            "rotat180 folder has been merged...\n",
            "Number of images in output: 180\n",
            "rotat210 folder has been merged...\n",
            "Number of images in output: 200\n",
            "rotat240 folder has been merged...\n",
            "Number of images in output: 220\n",
            "rotat270 folder has been merged...\n",
            "Number of images in output: 240\n",
            "rotat300 folder has been merged...\n",
            "Number of images in output: 260\n",
            "rotat330 folder has been merged...\n",
            "Number of images in output: 280\n",
            "flipping0_30 folder has been merged...\n",
            "Number of images in output: 300\n",
            "flipping0_60 folder has been merged...\n",
            "Number of images in output: 320\n",
            "flipping0_90 folder has been merged...\n",
            "Number of images in output: 340\n",
            "flipping0_120 folder has been merged...\n",
            "Number of images in output: 360\n",
            "flipping0_150 folder has been merged...\n",
            "Number of images in output: 380\n",
            "flipping0_180 folder has been merged...\n",
            "Number of images in output: 400\n",
            "flipping0_210 folder has been merged...\n",
            "Number of images in output: 420\n",
            "flipping0_240 folder has been merged...\n",
            "Number of images in output: 440\n",
            "flipping0_270 folder has been merged...\n",
            "Number of images in output: 460\n",
            "flipping0_300 folder has been merged...\n",
            "Number of images in output: 480\n",
            "flipping0_330 folder has been merged...\n",
            "Number of images in output: 500\n",
            "flipping1_30 folder has been merged...\n",
            "Number of images in output: 520\n",
            "flipping1_60 folder has been merged...\n",
            "Number of images in output: 540\n",
            "flipping1_90 folder has been merged...\n",
            "Number of images in output: 560\n",
            "flipping1_120 folder has been merged...\n",
            "Number of images in output: 580\n",
            "flipping1_150 folder has been merged...\n",
            "Number of images in output: 600\n",
            "flipping1_180 folder has been merged...\n",
            "Number of images in output: 620\n",
            "flipping1_210 folder has been merged...\n",
            "Number of images in output: 640\n",
            "flipping1_240 folder has been merged...\n",
            "Number of images in output: 660\n",
            "flipping1_270 folder has been merged...\n",
            "Number of images in output: 680\n",
            "flipping1_300 folder has been merged...\n",
            "Number of images in output: 700\n",
            "flipping1_330 folder has been merged...\n",
            "Number of images in output: 720\n",
            "zoom_out08 folder has been merged...\n",
            "Number of images in output: 740\n",
            "zoom_out08_30 folder has been merged...\n",
            "Number of images in output: 760\n",
            "zoom_out08_60 folder has been merged...\n",
            "Number of images in output: 780\n",
            "zoom_out08_90 folder has been merged...\n",
            "Number of images in output: 800\n",
            "zoom_out08_120 folder has been merged...\n",
            "Number of images in output: 820\n",
            "zoom_out08_180 folder has been merged...\n",
            "Number of images in output: 840\n",
            "zoom_out08_150 folder has been merged...\n",
            "Number of images in output: 860\n",
            "zoom_out08_210 folder has been merged...\n",
            "Number of images in output: 880\n",
            "zoom_out08_240 folder has been merged...\n",
            "Number of images in output: 900\n",
            "zoom_out08_270 folder has been merged...\n",
            "Number of images in output: 920\n",
            "zoom_out08_300 folder has been merged...\n",
            "Number of images in output: 940\n",
            "zoom_out08_330 folder has been merged...\n",
            "Number of images in output: 960\n",
            "white_noise folder has been merged...\n",
            "Number of images in output: 980\n",
            "white_noise90 folder has been merged...\n",
            "Number of images in output: 1000\n",
            "white_noise180 folder has been merged...\n",
            "Number of images in output: 1020\n",
            "white_noise270 folder has been merged...\n",
            "Number of images in output: 1040\n",
            "elastic folder has been merged...\n",
            "Number of images in output: 1060\n",
            "shifty_100 folder has been merged...\n",
            "Number of images in output: 1080\n",
            "shifty_-100 folder has been merged...\n",
            "Number of images in output: 1100\n",
            "shiftx_100 folder has been merged...\n",
            "Number of images in output: 1120\n",
            "shiftx_-100 folder has been merged...\n",
            "Number of images in output: 1140\n",
            "shifty_100_90 folder has been merged...\n",
            "Number of images in output: 1160\n",
            "shifty_100_180 folder has been merged...\n",
            "Number of images in output: 1180\n",
            "shifty_100_270 folder has been merged...\n",
            "Number of images in output: 1200\n",
            "shifty_-100_90 folder has been merged...\n",
            "Number of images in output: 1220\n",
            "shifty_-100_180 folder has been merged...\n",
            "Number of images in output: 1240\n",
            "shifty_-100_270 folder has been merged...\n",
            "Number of images in output: 1260\n",
            "shiftx_100_90 folder has been merged...\n",
            "Number of images in output: 1280\n",
            "shiftx_100_180 folder has been merged...\n",
            "Number of images in output: 1300\n",
            "shiftx_100_270 folder has been merged...\n",
            "Number of images in output: 1320\n",
            "shiftx_-100_90 folder has been merged...\n",
            "Number of images in output: 1340\n",
            "shiftx_-100_180 folder has been merged...\n",
            "Number of images in output: 1360\n",
            "shiftx_-100_270 folder has been merged...\n",
            "Number of images in output: 1380\n",
            "gamma_correction05 folder has been merged...\n",
            "Number of images in output: 1400\n",
            "gamma_correction05_30 folder has been merged...\n",
            "Number of images in output: 1420\n",
            "gamma_correction05_60 folder has been merged...\n",
            "Number of images in output: 1440\n",
            "gamma_correction05_90 folder has been merged...\n",
            "Number of images in output: 1460\n",
            "gamma_correction05_120 folder has been merged...\n",
            "Number of images in output: 1480\n",
            "gamma_correction05_150 folder has been merged...\n",
            "Number of images in output: 1500\n",
            "gamma_correction05_180 folder has been merged...\n",
            "Number of images in output: 1520\n",
            "gamma_correction05_210 folder has been merged...\n",
            "Number of images in output: 1540\n",
            "gamma_correction05_240 folder has been merged...\n",
            "Number of images in output: 1560\n",
            "gamma_correction05_270 folder has been merged...\n",
            "Number of images in output: 1580\n",
            "gamma_correction05_300 folder has been merged...\n",
            "Number of images in output: 1600\n",
            "gamma_correction05_330 folder has been merged...\n",
            "Number of images in output: 1620\n",
            "album_grid_dist folder has been merged...\n",
            "Number of images in output: 1640\n",
            "album_heavy folder has been merged...\n",
            "Number of images in output: 1660\n",
            "album_medium folder has been merged...\n",
            "Number of images in output: 1680\n",
            "album_optical folder has been merged...\n",
            "Number of images in output: 1700\n",
            "album_random_crop folder has been merged...\n",
            "Number of images in output: 1720\n",
            "album_grid_dist90 folder has been merged...\n",
            "Number of images in output: 1740\n",
            "album_grid_dist180 folder has been merged...\n",
            "Number of images in output: 1760\n",
            "album_grid_dist270 folder has been merged...\n",
            "Number of images in output: 1780\n",
            "album_heavy90 folder has been merged...\n",
            "Number of images in output: 1800\n",
            "album_heavy180 folder has been merged...\n",
            "Number of images in output: 1820\n",
            "album_heavy270 folder has been merged...\n",
            "Number of images in output: 1840\n",
            "album_medium90 folder has been merged...\n",
            "Number of images in output: 1860\n",
            "album_medium180 folder has been merged...\n",
            "Number of images in output: 1880\n",
            "album_medium270 folder has been merged...\n",
            "Number of images in output: 1900\n",
            "album_optical90 folder has been merged...\n",
            "Number of images in output: 1920\n",
            "album_optical180 folder has been merged...\n",
            "Number of images in output: 1940\n",
            "album_optical270 folder has been merged...\n",
            "Number of images in output: 1960\n",
            "album_random_crop2 folder has been merged...\n",
            "Number of images in output: 1980\n",
            "album_random_crop3 folder has been merged...\n",
            "Number of images in output: 2000\n",
            "album_random_crop4 folder has been merged...\n",
            "Number of images in output: 2020\n",
            "blurring3 folder has been merged...\n",
            "Number of images in output: 2040\n",
            "blurring5 folder has been merged...\n",
            "Number of images in output: 2060\n",
            "dropout folder has been merged...\n",
            "Number of images in output: 2080\n",
            "eq_hist folder has been merged...\n",
            "Number of images in output: 2100\n",
            "sharpen folder has been merged...\n",
            "Number of images in output: 2120\n",
            "Merging is done successfully!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1dEs6Xd4r4Bs"
      },
      "source": [
        "# Experimental Style Transfer Part"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rP8njHS4bWvt",
        "outputId": "038b2dbb-c954-4e74-d553-a5f768073db1"
      },
      "source": [
        "%tensorflow_version 1.x"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cnTHPqOo0DNP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d2979ee5-5ccb-4a91-b8ed-92747fcff18a"
      },
      "source": [
        "!pip install -q 'scipy<=1.2.1'  # scipy.misc.imread is deprecated in later versions"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |ââââââââââââââââââââââââââââââââ| 24.8MB 146kB/s \n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "\u001b[?25h"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LDS4ELQ-0R8M",
        "outputId": "4838c800-271c-4b01-c79a-17d362e54183"
      },
      "source": [
        "!git clone https://github.com/titu1994/Neural-Style-Transfer.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'Neural-Style-Transfer'...\n",
            "remote: Enumerating objects: 7, done.\u001b[K\n",
            "remote: Counting objects: 100% (7/7), done.\u001b[K\n",
            "remote: Compressing objects: 100% (7/7), done.\u001b[K\n",
            "remote: Total 1400 (delta 1), reused 3 (delta 0), pack-reused 1393\u001b[K\n",
            "Receiving objects: 100% (1400/1400), 68.16 MiB | 41.74 MiB/s, done.\n",
            "Resolving deltas: 100% (820/820), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xWpC6lGw0V30",
        "outputId": "3484e4f7-518c-49f1-d189-264182e081b6"
      },
      "source": [
        "cd Neural-Style-Transfer/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/Neural-Style-Transfer\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "WEvwxJ5G4HaM",
        "outputId": "f3b9971f-c6ec-4ddb-d169-985207b83717"
      },
      "source": [
        "pwd"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/Neural-Style-Transfer'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TOyO2J4gg0Bl"
      },
      "source": [
        "# SORRY FOR MESS BUT YOU MUST REPLACE INetwork.py FILE WITH LAST CELL BEFORE RUN BELOW "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bx5Q7rrIVy6f"
      },
      "source": [
        "LABEL_PATH   = \"/content/drive/MyDrive/AI_Projects/retina_DRIVE/png_data/train/labels\"\n",
        "IMG_PATH     = \"/content/drive/MyDrive/AI_Projects/retina_DRIVE/png_data/train/images\"\n",
        "RESULT_PATH  = \"/content/drive/MyDrive/AI_Projects/retina_DRIVE/png_data/style_transfer\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-zP5ab0m7-vS"
      },
      "source": [
        "import numpy as np\n",
        "import os\n",
        "from skimage.metrics import structural_similarity\n",
        "import cv2\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3jtFoVOG7-s-"
      },
      "source": [
        "def find_distances():\n",
        "  distances = np.zeros((20,20),dtype=float)\n",
        "  for i in sorted(os.listdir(IMG_PATH)):\n",
        "    for j in sorted(os.listdir(IMG_PATH)):\n",
        "      a = cv2.imread(IMG_PATH + '/' + i, 0)\n",
        "      b = cv2.imread(IMG_PATH + '/' + j, 0)\n",
        "\n",
        "      score, diff = structural_similarity(a, b, full=True)\n",
        "      distances[int(i.split('.')[0])][int(j.split('.')[0])] = float(score)\n",
        "\n",
        "  return distances"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DJ4fj9K09T3M"
      },
      "source": [
        "def style_transfer(n_of_iter = 10, content_weight = 0.025, style_weight = 1):\n",
        "  distances = np.zeros((20,20))\n",
        "  distances = find_distances()\n",
        "\n",
        "  result_img = RESULT_PATH + '/images'\n",
        "  result_label = RESULT_PATH + '/labels'\n",
        "\n",
        "  os.mkdir(result_img)\n",
        "  os.mkdir(result_label)\n",
        "\n",
        "  for i in sorted(os.listdir(IMG_PATH)):\n",
        "    furthest = distances[int(i.split('.')[0])].argmin()\n",
        "    furthest_value = distances[int(i.split('.')[0])].min()\n",
        "    os.system('python INetwork.py \"'+ IMG_PATH + '/' + i +'\" \"'+ IMG_PATH + '/' + str(furthest) + '.png' +'\" \"'+ result_img + '/'+ i.split('.')[0] + '\" --image_size 584 --num_iter '+ str(n_of_iter) +' --pool_type \"max\" --model \"vgg19\" --content_weight '+ str(content_weight) +' --style_weight ' + str(style_weight))\n",
        "    os.rename(result_img + '/' + i.split('.')[0] + '_style.png', result_img + '/style_' + i.split('.')[0] + '.png')\n",
        "    \n",
        "    a = cv2.imread(IMG_PATH + '/' + i, 0)\n",
        "    b = cv2.imread(result_img + '/style_' + i , 0)\n",
        "    score, diff = structural_similarity(a, b, full=True)\n",
        "    print(\"style_\" + i + \" saved successfully.\\nFurthest image from \" + i + \" is \" + str(furthest) + \" with similarity: \" + str(furthest_value) + \"\\nSimilarity between \" + i + \" and styled one is: \" + str(score) + \"\\n---------------------------------------------------------------------\") \n",
        "\n",
        "  os.system(\"rsync -a \"+ LABEL_PATH + \"/ \" + result_label)\n",
        "  for i in sorted(os.listdir(result_label)):\n",
        "    os.rename(result_label + '/' + i, result_label + '/style_' + i.split('.')[0] + '.png')\n",
        "  print('Label folder successfully copied from LABEL_PATH.')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eKhdVcCSr9Hm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "470309ed-f7c5-4ed3-cd49-394e8c937848"
      },
      "source": [
        "style_transfer(n_of_iter = 10, content_weight = 0.025, style_weight = 1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "style_0.png saved successfully.\n",
            "Furthest image from 0.png is 13 with similarity: 0.6581827873570326\n",
            "Similarity between 0.png and styled one is: 0.916427185561389\n",
            "---------------------------------------------------------------------\n",
            "style_1.png saved successfully.\n",
            "Furthest image from 1.png is 13 with similarity: 0.6545721609734262\n",
            "Similarity between 1.png and styled one is: 0.9423020593559593\n",
            "---------------------------------------------------------------------\n",
            "style_10.png saved successfully.\n",
            "Furthest image from 10.png is 13 with similarity: 0.6619912221219528\n",
            "Similarity between 10.png and styled one is: 0.9374854737404626\n",
            "---------------------------------------------------------------------\n",
            "style_11.png saved successfully.\n",
            "Furthest image from 11.png is 13 with similarity: 0.6916511963871375\n",
            "Similarity between 11.png and styled one is: 0.9240754506464935\n",
            "---------------------------------------------------------------------\n",
            "style_12.png saved successfully.\n",
            "Furthest image from 12.png is 13 with similarity: 0.6338797967488901\n",
            "Similarity between 12.png and styled one is: 0.9141204549069615\n",
            "---------------------------------------------------------------------\n",
            "style_13.png saved successfully.\n",
            "Furthest image from 13.png is 7 with similarity: 0.624444554107799\n",
            "Similarity between 13.png and styled one is: 0.9583120523693983\n",
            "---------------------------------------------------------------------\n",
            "style_14.png saved successfully.\n",
            "Furthest image from 14.png is 7 with similarity: 0.6805183818610163\n",
            "Similarity between 14.png and styled one is: 0.9805213558039678\n",
            "---------------------------------------------------------------------\n",
            "style_15.png saved successfully.\n",
            "Furthest image from 15.png is 13 with similarity: 0.666134240040633\n",
            "Similarity between 15.png and styled one is: 0.9663060672267942\n",
            "---------------------------------------------------------------------\n",
            "style_16.png saved successfully.\n",
            "Furthest image from 16.png is 2 with similarity: 0.6790913868102619\n",
            "Similarity between 16.png and styled one is: 0.9557142463168761\n",
            "---------------------------------------------------------------------\n",
            "style_17.png saved successfully.\n",
            "Furthest image from 17.png is 13 with similarity: 0.6385782345629184\n",
            "Similarity between 17.png and styled one is: 0.9190484542479569\n",
            "---------------------------------------------------------------------\n",
            "style_18.png saved successfully.\n",
            "Furthest image from 18.png is 13 with similarity: 0.6712383287858426\n",
            "Similarity between 18.png and styled one is: 0.9474391361970734\n",
            "---------------------------------------------------------------------\n",
            "style_19.png saved successfully.\n",
            "Furthest image from 19.png is 13 with similarity: 0.6733169819898165\n",
            "Similarity between 19.png and styled one is: 0.95581547076174\n",
            "---------------------------------------------------------------------\n",
            "style_2.png saved successfully.\n",
            "Furthest image from 2.png is 13 with similarity: 0.631272105491605\n",
            "Similarity between 2.png and styled one is: 0.9277425172637959\n",
            "---------------------------------------------------------------------\n",
            "style_3.png saved successfully.\n",
            "Furthest image from 3.png is 13 with similarity: 0.6608479765838711\n",
            "Similarity between 3.png and styled one is: 0.9098358361276108\n",
            "---------------------------------------------------------------------\n",
            "style_4.png saved successfully.\n",
            "Furthest image from 4.png is 13 with similarity: 0.6918866010243693\n",
            "Similarity between 4.png and styled one is: 0.9438943953600281\n",
            "---------------------------------------------------------------------\n",
            "style_5.png saved successfully.\n",
            "Furthest image from 5.png is 7 with similarity: 0.6700406071202143\n",
            "Similarity between 5.png and styled one is: 0.94622153243222\n",
            "---------------------------------------------------------------------\n",
            "style_6.png saved successfully.\n",
            "Furthest image from 6.png is 13 with similarity: 0.6799699271706624\n",
            "Similarity between 6.png and styled one is: 0.927807455739216\n",
            "---------------------------------------------------------------------\n",
            "style_7.png saved successfully.\n",
            "Furthest image from 7.png is 13 with similarity: 0.624444554107799\n",
            "Similarity between 7.png and styled one is: 0.9404183639875214\n",
            "---------------------------------------------------------------------\n",
            "style_8.png saved successfully.\n",
            "Furthest image from 8.png is 13 with similarity: 0.6802863465171148\n",
            "Similarity between 8.png and styled one is: 0.9642322218954821\n",
            "---------------------------------------------------------------------\n",
            "style_9.png saved successfully.\n",
            "Furthest image from 9.png is 7 with similarity: 0.6752211439943647\n",
            "Similarity between 9.png and styled one is: 0.946276587315474\n",
            "---------------------------------------------------------------------\n",
            "Label folder successfully copied from LABEL_PATH.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_cQzGB9fRBza"
      },
      "source": [
        "from __future__ import print_function\n",
        "from __future__ import division\n",
        "from __future__ import absolute_import\n",
        "\n",
        "# from scipy.misc import imread, imresize, imsave, fromimage, toimage\n",
        "from utils import imread, imresize, imsave, fromimage, toimage\n",
        "\n",
        "from scipy.optimize import fmin_l_bfgs_b\n",
        "import numpy as np\n",
        "import time\n",
        "import argparse\n",
        "import warnings\n",
        "\n",
        "from keras.models import Model\n",
        "from keras.layers import Input\n",
        "from keras.layers.convolutional import Convolution2D, AveragePooling2D, MaxPooling2D\n",
        "from keras import backend as K\n",
        "from keras.utils.data_utils import get_file\n",
        "from keras.utils.layer_utils import convert_all_kernels_in_model\n",
        "\n",
        "\"\"\"\n",
        "Neural Style Transfer with Keras 2.0.5\n",
        "\n",
        "Based on:\n",
        "https://github.com/fchollet/keras/blob/master/examples/neural_style_transfer.py\n",
        "\n",
        "Contains few improvements suggested in the paper Improving the Neural Algorithm of Artistic Style\n",
        "(http://arxiv.org/abs/1605.04603).\n",
        "\n",
        "-----------------------------------------------------------------------------------------------------------------------\n",
        "\"\"\"\n",
        "\n",
        "THEANO_WEIGHTS_PATH_NO_TOP = 'https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_th_dim_ordering_th_kernels_notop.h5'\n",
        "TF_WEIGHTS_PATH_NO_TOP = 'https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
        "\n",
        "TH_19_WEIGHTS_PATH_NO_TOP = 'https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg19_weights_th_dim_ordering_th_kernels_notop.h5'\n",
        "TF_19_WEIGHTS_PATH_NO_TOP = 'https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
        "\n",
        "\n",
        "parser = argparse.ArgumentParser(description='Neural style transfer with Keras.')\n",
        "parser.add_argument('base_image_path', metavar='base', type=str,\n",
        "                    help='Path to the image to transform.')\n",
        "\n",
        "parser.add_argument('syle_image_paths', metavar='ref', nargs='+', type=str,\n",
        "                    help='Path to the style reference image.')\n",
        "\n",
        "parser.add_argument('result_prefix', metavar='res_prefix', type=str,\n",
        "                    help='Prefix for the saved results.')\n",
        "\n",
        "parser.add_argument(\"--style_masks\", type=str, default=None, nargs='+',\n",
        "                    help='Masks for style images')\n",
        "\n",
        "parser.add_argument(\"--content_mask\", type=str, default=None,\n",
        "                    help='Masks for the content image')\n",
        "\n",
        "parser.add_argument(\"--color_mask\", type=str, default=None,\n",
        "                    help='Mask for color preservation')\n",
        "\n",
        "parser.add_argument(\"--image_size\", dest=\"img_size\", default=400, type=int,\n",
        "                    help='Minimum image size')\n",
        "\n",
        "parser.add_argument(\"--content_weight\", dest=\"content_weight\", default=0.025, type=float,\n",
        "                    help=\"Weight of content\")\n",
        "\n",
        "parser.add_argument(\"--style_weight\", dest=\"style_weight\", nargs='+', default=[1], type=float,\n",
        "                    help=\"Weight of style, can be multiple for multiple styles\")\n",
        "\n",
        "parser.add_argument(\"--style_scale\", dest=\"style_scale\", default=1.0, type=float,\n",
        "                    help=\"Scale the weighing of the style\")\n",
        "\n",
        "parser.add_argument(\"--total_variation_weight\", dest=\"tv_weight\", default=8.5e-5, type=float,\n",
        "                    help=\"Total Variation weight\")\n",
        "\n",
        "parser.add_argument(\"--num_iter\", dest=\"num_iter\", default=10, type=int,\n",
        "                    help=\"Number of iterations\")\n",
        "\n",
        "parser.add_argument(\"--model\", default=\"vgg16\", type=str,\n",
        "                    help=\"Choices are 'vgg16' and 'vgg19'\")\n",
        "\n",
        "parser.add_argument(\"--content_loss_type\", default=0, type=int,\n",
        "                    help='Can be one of 0, 1 or 2. Readme contains the required information of each mode.')\n",
        "\n",
        "parser.add_argument(\"--rescale_image\", dest=\"rescale_image\", default=\"False\", type=str,\n",
        "                    help=\"Rescale image after execution to original dimentions\")\n",
        "\n",
        "parser.add_argument(\"--rescale_method\", dest=\"rescale_method\", default=\"bilinear\", type=str,\n",
        "                    help=\"Rescale image algorithm\")\n",
        "\n",
        "parser.add_argument(\"--maintain_aspect_ratio\", dest=\"maintain_aspect_ratio\", default=\"True\", type=str,\n",
        "                    help=\"Maintain aspect ratio of loaded images\")\n",
        "\n",
        "parser.add_argument(\"--content_layer\", dest=\"content_layer\", default=\"conv5_2\", type=str,\n",
        "                    help=\"Content layer used for content loss.\")\n",
        "\n",
        "parser.add_argument(\"--init_image\", dest=\"init_image\", default=\"content\", type=str,\n",
        "                    help=\"Initial image used to generate the final image. Options are 'content', 'noise', or 'gray'\")\n",
        "\n",
        "parser.add_argument(\"--pool_type\", dest=\"pool\", default=\"max\", type=str,\n",
        "                    help='Pooling type. Can be \"ave\" for average pooling or \"max\" for max pooling')\n",
        "\n",
        "parser.add_argument('--preserve_color', dest='color', default=\"False\", type=str,\n",
        "                    help='Preserve original color in image')\n",
        "\n",
        "parser.add_argument('--min_improvement', default=0.0, type=float,\n",
        "                    help='Defines minimum improvement required to continue script')\n",
        "\n",
        "\n",
        "def str_to_bool(v):\n",
        "    return v.lower() in (\"true\", \"yes\", \"t\", \"1\")\n",
        "\n",
        "''' Arguments '''\n",
        "\n",
        "args = parser.parse_args()\n",
        "base_image_path = args.base_image_path\n",
        "style_reference_image_paths = args.syle_image_paths\n",
        "result_prefix = args.result_prefix\n",
        "\n",
        "style_image_paths = []\n",
        "for style_image_path in style_reference_image_paths:\n",
        "    style_image_paths.append(style_image_path)\n",
        "\n",
        "style_masks_present = args.style_masks is not None\n",
        "mask_paths = []\n",
        "\n",
        "if style_masks_present:\n",
        "    for mask_path in args.style_masks:\n",
        "        mask_paths.append(mask_path)\n",
        "\n",
        "if style_masks_present:\n",
        "    assert len(style_image_paths) == len(mask_paths), \"Wrong number of style masks provided.\\n\" \\\n",
        "                                                      \"Number of style images = %d, \\n\" \\\n",
        "                                                      \"Number of style mask paths = %d.\" % \\\n",
        "                                                      (len(style_image_paths), len(style_masks_present))\n",
        "\n",
        "content_mask_present = args.content_mask is not None\n",
        "content_mask_path = args.content_mask\n",
        "\n",
        "\n",
        "color_mask_present = args.color_mask is not None\n",
        "\n",
        "rescale_image = str_to_bool(args.rescale_image)\n",
        "maintain_aspect_ratio = str_to_bool(args.maintain_aspect_ratio)\n",
        "preserve_color = str_to_bool(args.color)\n",
        "\n",
        "# these are the weights of the different loss components\n",
        "content_weight = args.content_weight\n",
        "total_variation_weight = args.tv_weight\n",
        "\n",
        "style_weights = []\n",
        "\n",
        "if len(style_image_paths) != len(args.style_weight):\n",
        "    print(\"Mismatch in number of style images provided and number of style weights provided. \\n\"\n",
        "          \"Found %d style images and %d style weights. \\n\"\n",
        "          \"Equally distributing weights to all other styles.\" % (len(style_image_paths), len(args.style_weight)))\n",
        "\n",
        "    weight_sum = sum(args.style_weight) * args.style_scale\n",
        "    count = len(style_image_paths)\n",
        "\n",
        "    for i in range(len(style_image_paths)):\n",
        "        style_weights.append(weight_sum / count)\n",
        "else:\n",
        "    for style_weight in args.style_weight:\n",
        "        style_weights.append(style_weight * args.style_scale)\n",
        "\n",
        "# Decide pooling function\n",
        "pooltype = str(args.pool).lower()\n",
        "assert pooltype in [\"ave\", \"max\"], 'Pooling argument is wrong. Needs to be either \"ave\" or \"max\".'\n",
        "\n",
        "pooltype = 1 if pooltype == \"ave\" else 0\n",
        "\n",
        "read_mode = \"gray\" if args.init_image == \"gray\" else \"color\"\n",
        "\n",
        "# dimensions of the generated picture.\n",
        "img_width = img_height = 0\n",
        "\n",
        "img_WIDTH = img_HEIGHT = 0\n",
        "aspect_ratio = 0\n",
        "\n",
        "assert args.content_loss_type in [0, 1, 2], \"Content Loss Type must be one of 0, 1 or 2\"\n",
        "\n",
        "\n",
        "# util function to open, resize and format pictures into appropriate tensors\n",
        "def preprocess_image(image_path, load_dims=False, read_mode=\"color\"):\n",
        "    global img_width, img_height, img_WIDTH, img_HEIGHT, aspect_ratio\n",
        "\n",
        "    mode = \"RGB\" if read_mode == \"color\" else \"L\"\n",
        "    img = imread(image_path, mode=mode)  # Prevents crashes due to PNG images (ARGB)\n",
        "\n",
        "    if mode == \"L\":\n",
        "        # Expand the 1 channel grayscale to 3 channel grayscale image\n",
        "        temp = np.zeros(img.shape + (3,), dtype=np.uint8)\n",
        "        temp[:, :, 0] = img\n",
        "        temp[:, :, 1] = img.copy()\n",
        "        temp[:, :, 2] = img.copy()\n",
        "\n",
        "        img = temp\n",
        "\n",
        "    if load_dims:\n",
        "        img_WIDTH = img.shape[0]\n",
        "        img_HEIGHT = img.shape[1]\n",
        "        aspect_ratio = float(img_HEIGHT) / img_WIDTH\n",
        "\n",
        "        img_width = args.img_size\n",
        "        if maintain_aspect_ratio:\n",
        "            img_height = int(img_width * aspect_ratio)\n",
        "        else:\n",
        "            img_height = args.img_size\n",
        "\n",
        "    img = imresize(img, (img_width, img_height)).astype('float32')\n",
        "\n",
        "    # RGB -> BGR\n",
        "    img = img[:, :, ::-1]\n",
        "\n",
        "    img[:, :, 0] -= 103.939\n",
        "    img[:, :, 1] -= 116.779\n",
        "    img[:, :, 2] -= 123.68\n",
        "\n",
        "    if K.image_data_format() == \"channels_first\":\n",
        "        img = img.transpose((2, 0, 1)).astype('float32')\n",
        "\n",
        "    img = np.expand_dims(img, axis=0)\n",
        "    return img\n",
        "\n",
        "\n",
        "# util function to convert a tensor into a valid image\n",
        "def deprocess_image(x):\n",
        "    if K.image_data_format() == \"channels_first\":\n",
        "        x = x.reshape((3, img_width, img_height))\n",
        "        x = x.transpose((1, 2, 0))\n",
        "    else:\n",
        "        x = x.reshape((img_width, img_height, 3))\n",
        "\n",
        "    x[:, :, 0] += 103.939\n",
        "    x[:, :, 1] += 116.779\n",
        "    x[:, :, 2] += 123.68\n",
        "\n",
        "    # BGR -> RGB\n",
        "    x = x[:, :, ::-1]\n",
        "\n",
        "    x = np.clip(x, 0, 255).astype('uint8')\n",
        "    return x\n",
        "\n",
        "\n",
        "# util function to preserve image color\n",
        "def original_color_transform(content, generated, mask=None):\n",
        "    generated = fromimage(toimage(generated, mode='RGB'), mode='YCbCr')  # Convert to YCbCr color space\n",
        "\n",
        "    if mask is None:\n",
        "        generated[:, :, 1:] = content[:, :, 1:]  # Generated CbCr = Content CbCr\n",
        "    else:\n",
        "        width, height, channels = generated.shape\n",
        "\n",
        "        for i in range(width):\n",
        "            for j in range(height):\n",
        "                if mask[i, j] == 1:\n",
        "                    generated[i, j, 1:] = content[i, j, 1:]\n",
        "\n",
        "    generated = fromimage(toimage(generated, mode='YCbCr'), mode='RGB')  # Convert to RGB color space\n",
        "    return generated\n",
        "\n",
        "\n",
        "def load_mask(mask_path, shape, return_mask_img=False):\n",
        "    if K.image_data_format() == \"channels_first\":\n",
        "        _, channels, width, height = shape\n",
        "    else:\n",
        "        _, width, height, channels = shape\n",
        "\n",
        "    mask = imread(mask_path, mode=\"L\") # Grayscale mask load\n",
        "    mask = imresize(mask, (width, height)).astype('float32')\n",
        "\n",
        "    # Perform binarization of mask\n",
        "    mask[mask <= 127] = 0\n",
        "    mask[mask > 128] = 255\n",
        "\n",
        "    max = np.amax(mask)\n",
        "    mask /= max\n",
        "\n",
        "    if return_mask_img: return mask\n",
        "\n",
        "    mask_shape = shape[1:]\n",
        "\n",
        "    mask_tensor = np.empty(mask_shape)\n",
        "\n",
        "    for i in range(channels):\n",
        "        if K.image_data_format() == \"channels_first\":\n",
        "            mask_tensor[i, :, :] = mask\n",
        "        else:\n",
        "            mask_tensor[:, :, i] = mask\n",
        "\n",
        "    return mask_tensor\n",
        "\n",
        "\n",
        "def pooling_func(x):\n",
        "    if pooltype == 1:\n",
        "        return AveragePooling2D((2, 2), strides=(2, 2))(x)\n",
        "    else:\n",
        "        return MaxPooling2D((2, 2), strides=(2, 2))(x)\n",
        "\n",
        "\n",
        "# get tensor representations of our images\n",
        "base_image = K.variable(preprocess_image(base_image_path, True, read_mode=read_mode))\n",
        "\n",
        "style_reference_images = []\n",
        "for style_path in style_image_paths:\n",
        "    style_reference_images.append(K.variable(preprocess_image(style_path)))\n",
        "\n",
        "# this will contain our generated image\n",
        "if K.image_data_format() == \"channels_first\":\n",
        "    combination_image = K.placeholder((1, 3, img_width, img_height))\n",
        "else:\n",
        "    combination_image = K.placeholder((1, img_width, img_height, 3))\n",
        "\n",
        "image_tensors = [base_image]\n",
        "for style_image_tensor in style_reference_images:\n",
        "    image_tensors.append(style_image_tensor)\n",
        "image_tensors.append(combination_image)\n",
        "\n",
        "nb_tensors = len(image_tensors)\n",
        "nb_style_images = nb_tensors - 2 # Content and Output image not considered\n",
        "\n",
        "# combine the various images into a single Keras tensor\n",
        "input_tensor = K.concatenate(image_tensors, axis=0)\n",
        "\n",
        "if K.image_data_format() == \"channels_first\":\n",
        "    shape = (nb_tensors, 3, img_width, img_height)\n",
        "else:\n",
        "    shape = (nb_tensors, img_width, img_height, 3)\n",
        "\n",
        "ip = Input(tensor=input_tensor, batch_shape=shape)\n",
        "\n",
        "# build the VGG16 network with our 3 images as input\n",
        "x = Convolution2D(64, (3, 3), activation='relu', name='conv1_1', padding='same')(ip)\n",
        "x = Convolution2D(64, (3, 3), activation='relu', name='conv1_2', padding='same')(x)\n",
        "x = pooling_func(x)\n",
        "\n",
        "x = Convolution2D(128, (3, 3), activation='relu', name='conv2_1', padding='same')(x)\n",
        "x = Convolution2D(128, (3, 3), activation='relu', name='conv2_2', padding='same')(x)\n",
        "x = pooling_func(x)\n",
        "\n",
        "x = Convolution2D(256, (3, 3), activation='relu', name='conv3_1', padding='same')(x)\n",
        "x = Convolution2D(256, (3, 3), activation='relu', name='conv3_2', padding='same')(x)\n",
        "x = Convolution2D(256, (3, 3), activation='relu', name='conv3_3', padding='same')(x)\n",
        "if args.model == \"vgg19\":\n",
        "    x = Convolution2D(256, (3, 3), activation='relu', name='conv3_4', padding='same')(x)\n",
        "x = pooling_func(x)\n",
        "\n",
        "x = Convolution2D(512, (3, 3), activation='relu', name='conv4_1', padding='same')(x)\n",
        "x = Convolution2D(512, (3, 3), activation='relu', name='conv4_2', padding='same')(x)\n",
        "x = Convolution2D(512, (3, 3), activation='relu', name='conv4_3', padding='same')(x)\n",
        "if args.model == \"vgg19\":\n",
        "    x = Convolution2D(512, (3, 3), activation='relu', name='conv4_4', padding='same')(x)\n",
        "x = pooling_func(x)\n",
        "\n",
        "x = Convolution2D(512, (3, 3), activation='relu', name='conv5_1', padding='same')(x)\n",
        "x = Convolution2D(512, (3, 3), activation='relu', name='conv5_2', padding='same')(x)\n",
        "x = Convolution2D(512, (3, 3), activation='relu', name='conv5_3', padding='same')(x)\n",
        "if args.model == \"vgg19\":\n",
        "    x = Convolution2D(512, (3, 3), activation='relu', name='conv5_4', padding='same')(x)\n",
        "x = pooling_func(x)\n",
        "\n",
        "model = Model(ip, x)\n",
        "\n",
        "if K.image_data_format() == \"channels_first\":\n",
        "    if args.model == \"vgg19\":\n",
        "        weights = get_file('vgg19_weights_th_dim_ordering_th_kernels_notop.h5', TH_19_WEIGHTS_PATH_NO_TOP, cache_subdir='models')\n",
        "    else:\n",
        "        weights = get_file('vgg16_weights_th_dim_ordering_th_kernels_notop.h5', THEANO_WEIGHTS_PATH_NO_TOP, cache_subdir='models')\n",
        "else:\n",
        "    if args.model == \"vgg19\":\n",
        "        weights = get_file('vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5', TF_19_WEIGHTS_PATH_NO_TOP, cache_subdir='models')\n",
        "    else:\n",
        "        weights = get_file('vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5', TF_WEIGHTS_PATH_NO_TOP, cache_subdir='models')\n",
        "\n",
        "model.load_weights(weights)\n",
        "\n",
        "if K.backend() == 'tensorflow' and K.image_data_format() == \"channels_first\":\n",
        "    warnings.warn('You are using the TensorFlow backend, yet you '\n",
        "                  'are using the Theano '\n",
        "                  'image dimension ordering convention '\n",
        "                  '(`image_dim_ordering=\"th\"`). '\n",
        "                  'For best performance, set '\n",
        "                  '`image_dim_ordering=\"tf\"` in '\n",
        "                  'your Keras config '\n",
        "                  'at ~/.keras/keras.json.')\n",
        "    convert_all_kernels_in_model(model)\n",
        "\n",
        "print('Model loaded.')\n",
        "\n",
        "# get the symbolic outputs of each \"key\" layer (we gave them unique names).\n",
        "outputs_dict = dict([(layer.name, layer.output) for layer in model.layers])\n",
        "shape_dict = dict([(layer.name, layer.output_shape) for layer in model.layers])\n",
        "\n",
        "# compute the neural style loss\n",
        "# first we need to define 4 util functions\n",
        "\n",
        "# Improvement 1\n",
        "# the gram matrix of an image tensor (feature-wise outer product) using shifted activations\n",
        "def gram_matrix(x):\n",
        "    assert K.ndim(x) == 3\n",
        "    if K.image_data_format() == \"channels_first\":\n",
        "        features = K.batch_flatten(x)\n",
        "    else:\n",
        "        features = K.batch_flatten(K.permute_dimensions(x, (2, 0, 1)))\n",
        "    gram = K.dot(features - 1, K.transpose(features - 1))\n",
        "    return gram\n",
        "\n",
        "\n",
        "# the \"style loss\" is designed to maintain\n",
        "# the style of the reference image in the generated image.\n",
        "# It is based on the gram matrices (which capture style) of\n",
        "# feature maps from the style reference image\n",
        "# and from the generated image\n",
        "def style_loss(style, combination, mask_path=None, nb_channels=None):\n",
        "    assert K.ndim(style) == 3\n",
        "    assert K.ndim(combination) == 3\n",
        "\n",
        "    if content_mask_path is not None:\n",
        "        content_mask = K.variable(load_mask(content_mask_path, nb_channels))\n",
        "        combination = combination * K.stop_gradient(content_mask)\n",
        "        del content_mask\n",
        "\n",
        "    if mask_path is not None:\n",
        "        style_mask = K.variable(load_mask(mask_path, nb_channels))\n",
        "        style = style * K.stop_gradient(style_mask)\n",
        "        if content_mask_path is None:\n",
        "            combination = combination * K.stop_gradient(style_mask)\n",
        "        del style_mask\n",
        "\n",
        "    S = gram_matrix(style)\n",
        "    C = gram_matrix(combination)\n",
        "    channels = 3\n",
        "    size = img_width * img_height\n",
        "    return K.sum(K.square(S - C)) / (4. * (channels ** 2) * (size ** 2))\n",
        "\n",
        "\n",
        "# an auxiliary loss function\n",
        "# designed to maintain the \"content\" of the\n",
        "# base image in the generated image\n",
        "def content_loss(base, combination):\n",
        "    channel_dim = 0 if K.image_data_format() == \"channels_first\" else -1\n",
        "\n",
        "    try:\n",
        "        channels = K.int_shape(base)[channel_dim]\n",
        "    except TypeError:\n",
        "        channels = K.shape(base)[channel_dim]\n",
        "    size = img_width * img_height\n",
        "\n",
        "    if args.content_loss_type == 1:\n",
        "        multiplier = 1. / (2. * (channels ** 0.5) * (size ** 0.5))\n",
        "    elif args.content_loss_type == 2:\n",
        "        multiplier = 1. / (channels * size)\n",
        "    else:\n",
        "        multiplier = 1.\n",
        "\n",
        "    return multiplier * K.sum(K.square(combination - base))\n",
        "\n",
        "\n",
        "# the 3rd loss function, total variation loss,\n",
        "# designed to keep the generated image locally coherent\n",
        "def total_variation_loss(x):\n",
        "    assert K.ndim(x) == 4\n",
        "    if K.image_data_format() == \"channels_first\":\n",
        "        a = K.square(x[:, :, :img_width - 1, :img_height - 1] - x[:, :, 1:, :img_height - 1])\n",
        "        b = K.square(x[:, :, :img_width - 1, :img_height - 1] - x[:, :, :img_width - 1, 1:])\n",
        "    else:\n",
        "        a = K.square(x[:, :img_width - 1, :img_height - 1, :] - x[:, 1:, :img_height - 1, :])\n",
        "        b = K.square(x[:, :img_width - 1, :img_height - 1, :] - x[:, :img_width - 1, 1:, :])\n",
        "    return K.sum(K.pow(a + b, 1.25))\n",
        "\n",
        "if args.model == \"vgg19\":\n",
        "    feature_layers = ['conv1_1', 'conv1_2', 'conv2_1', 'conv2_2', 'conv3_1', 'conv3_2', 'conv3_3', 'conv3_4',\n",
        "                      'conv4_1', 'conv4_2', 'conv4_3', 'conv4_4', 'conv5_1', 'conv5_2', 'conv5_3', 'conv5_4']\n",
        "else:\n",
        "    feature_layers = ['conv1_1', 'conv1_2', 'conv2_1', 'conv2_2', 'conv3_1', 'conv3_2', 'conv3_3',\n",
        "                      'conv4_1', 'conv4_2', 'conv4_3', 'conv5_1', 'conv5_2', 'conv5_3']\n",
        "\n",
        "# combine these loss functions into a single scalar\n",
        "loss = K.variable(0.)\n",
        "layer_features = outputs_dict[args.content_layer]\n",
        "base_image_features = layer_features[0, :, :, :]\n",
        "combination_features = layer_features[nb_tensors - 1, :, :, :]\n",
        "loss = loss + content_weight * content_loss(base_image_features,\n",
        "                                      combination_features)\n",
        "# Improvement 2\n",
        "# Use all layers for style feature extraction and reconstruction\n",
        "nb_layers = len(feature_layers) - 1\n",
        "\n",
        "style_masks = []\n",
        "if style_masks_present:\n",
        "    style_masks = mask_paths # If mask present, pass dictionary of masks to style loss\n",
        "else:\n",
        "    style_masks = [None for _ in range(nb_style_images)] # If masks not present, pass None to the style loss\n",
        "\n",
        "channel_index = 1 if K.image_data_format() == \"channels_first\" else -1\n",
        "\n",
        "# Improvement 3 : Chained Inference without blurring\n",
        "for i in range(len(feature_layers) - 1):\n",
        "    layer_features = outputs_dict[feature_layers[i]]\n",
        "    shape = shape_dict[feature_layers[i]]\n",
        "    combination_features = layer_features[nb_tensors - 1, :, :, :]\n",
        "    style_reference_features = layer_features[1:nb_tensors - 1, :, :, :]\n",
        "    sl1 = []\n",
        "    for j in range(nb_style_images):\n",
        "        sl1.append(style_loss(style_reference_features[j], combination_features, style_masks[j], shape))\n",
        "\n",
        "    layer_features = outputs_dict[feature_layers[i + 1]]\n",
        "    shape = shape_dict[feature_layers[i + 1]]\n",
        "    combination_features = layer_features[nb_tensors - 1, :, :, :]\n",
        "    style_reference_features = layer_features[1:nb_tensors - 1, :, :, :]\n",
        "    sl2 = []\n",
        "    for j in range(nb_style_images):\n",
        "        sl2.append(style_loss(style_reference_features[j], combination_features, style_masks[j], shape))\n",
        "\n",
        "    for j in range(nb_style_images):\n",
        "        sl = sl1[j] - sl2[j]\n",
        "\n",
        "        # Improvement 4\n",
        "        # Geometric weighted scaling of style loss\n",
        "        loss = loss + (style_weights[j] / (2 ** (nb_layers - (i + 1)))) * sl\n",
        "\n",
        "loss = loss + total_variation_weight * total_variation_loss(combination_image)\n",
        "\n",
        "# get the gradients of the generated image wrt the loss\n",
        "grads = K.gradients(loss, combination_image)\n",
        "\n",
        "outputs = [loss]\n",
        "if type(grads) in {list, tuple}:\n",
        "    outputs += grads\n",
        "else:\n",
        "    outputs.append(grads)\n",
        "\n",
        "f_outputs = K.function([combination_image], outputs)\n",
        "\n",
        "\n",
        "def eval_loss_and_grads(x):\n",
        "    if K.image_data_format() == \"channels_first\":\n",
        "        x = x.reshape((1, 3, img_width, img_height))\n",
        "    else:\n",
        "        x = x.reshape((1, img_width, img_height, 3))\n",
        "    outs = f_outputs([x])\n",
        "    loss_value = outs[0]\n",
        "    if len(outs[1:]) == 1:\n",
        "        grad_values = outs[1].flatten().astype('float64')\n",
        "    else:\n",
        "        grad_values = np.array(outs[1:]).flatten().astype('float64')\n",
        "    return loss_value, grad_values\n",
        "\n",
        "\n",
        "# this Evaluator class makes it possible\n",
        "# to compute loss and gradients in one pass\n",
        "# while retrieving them via two separate functions,\n",
        "# \"loss\" and \"grads\". This is done because scipy.optimize\n",
        "# requires separate functions for loss and gradients,\n",
        "# but computing them separately would be inefficient.\n",
        "class Evaluator(object):\n",
        "    def __init__(self):\n",
        "        self.loss_value = None\n",
        "        self.grads_values = None\n",
        "\n",
        "    def loss(self, x):\n",
        "        assert self.loss_value is None\n",
        "        loss_value, grad_values = eval_loss_and_grads(x)\n",
        "        self.loss_value = loss_value\n",
        "        self.grad_values = grad_values\n",
        "        return self.loss_value\n",
        "\n",
        "    def grads(self, x):\n",
        "        assert self.loss_value is not None\n",
        "        grad_values = np.copy(self.grad_values)\n",
        "        self.loss_value = None\n",
        "        self.grad_values = None\n",
        "        return grad_values\n",
        "\n",
        "\n",
        "evaluator = Evaluator()\n",
        "\n",
        "# run scipy-based optimization (L-BFGS) over the pixels of the generated image\n",
        "# so as to minimize the neural style loss\n",
        "\n",
        "\n",
        "if \"content\" in args.init_image or \"gray\" in args.init_image:\n",
        "    x = preprocess_image(base_image_path, True, read_mode=read_mode)\n",
        "elif \"noise\" in args.init_image:\n",
        "    x = np.random.uniform(0, 255, (1, img_width, img_height, 3)) - 128.\n",
        "\n",
        "    if K.image_data_format() == \"channels_first\":\n",
        "        x = x.transpose((0, 3, 1, 2))\n",
        "else:\n",
        "    print(\"Using initial image : \", args.init_image)\n",
        "    x = preprocess_image(args.init_image, read_mode=read_mode)\n",
        "\n",
        "# We require original image if we are to preserve color in YCbCr mode\n",
        "if preserve_color:\n",
        "    content = imread(base_image_path, mode=\"YCbCr\")\n",
        "    content = imresize(content, (img_width, img_height))\n",
        "\n",
        "    if color_mask_present:\n",
        "        if K.image_data_format() == \"channels_first\":\n",
        "            color_mask_shape = (None, None, img_width, img_height)\n",
        "        else:\n",
        "            color_mask_shape = (None, img_width, img_height, None)\n",
        "\n",
        "        color_mask = load_mask(args.color_mask, color_mask_shape, return_mask_img=True)\n",
        "    else:\n",
        "        color_mask = None\n",
        "else:\n",
        "    color_mask = None\n",
        "\n",
        "num_iter = args.num_iter\n",
        "prev_min_val = -1\n",
        "\n",
        "improvement_threshold = float(args.min_improvement)\n",
        "\n",
        "for i in range(num_iter):\n",
        "    print(\"Starting iteration %d of %d\" % ((i + 1), num_iter))\n",
        "    start_time = time.time()\n",
        "\n",
        "    x, min_val, info = fmin_l_bfgs_b(evaluator.loss, x.flatten(), fprime=evaluator.grads, maxfun=20)\n",
        "\n",
        "    if prev_min_val == -1:\n",
        "        prev_min_val = min_val\n",
        "\n",
        "    improvement = (prev_min_val - min_val) / prev_min_val * 100\n",
        "\n",
        "    print(\"Current loss value:\", min_val, \" Improvement : %0.3f\" % improvement, \"%\")\n",
        "    prev_min_val = min_val\n",
        "    # save current generated image\n",
        "    img = deprocess_image(x.copy())\n",
        "\n",
        "    if preserve_color and content is not None:\n",
        "        img = original_color_transform(content, img, mask=color_mask)\n",
        "\n",
        "    if not rescale_image:\n",
        "        img_ht = int(img_width * aspect_ratio)\n",
        "        print(\"Rescaling Image to (%d, %d)\" % (img_width, img_ht))\n",
        "        img = imresize(img, (img_width, img_ht), interp=args.rescale_method)\n",
        "\n",
        "    if rescale_image:\n",
        "        print(\"Rescaling Image to (%d, %d)\" % (img_WIDTH, img_HEIGHT))\n",
        "        img = imresize(img, (img_WIDTH, img_HEIGHT), interp=args.rescale_method)\n",
        "    if i == num_iter-1:\n",
        "      fname = result_prefix + \"_style.png\"\n",
        "      imsave(fname, img)\n",
        "      print(\"Image saved as\", fname)\n",
        "    end_time = time.time()\n",
        "    \n",
        "    print(\"Iteration %d completed in %ds\" % (i + 1, end_time - start_time))\n",
        "\n",
        "    if improvement_threshold is not 0.0:\n",
        "        if improvement < improvement_threshold and improvement is not 0.0:\n",
        "            print(\"Improvement (%f) is less than improvement threshold (%f). Early stopping script.\" %\n",
        "                  (improvement, improvement_threshold))\n",
        "            exit()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oCI1YhDucBiR"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uqJV-y9nh8QG"
      },
      "source": [
        "#A\n",
        "len(['train', \n",
        "                     'flipping0', \n",
        "                     'flipping1', \n",
        "                     'rotation30', \n",
        "                     'rotation60', \n",
        "                     'rotation90', \n",
        "                     'rotation120', \n",
        "                     'rotation150', \n",
        "                     'rotation180', \n",
        "                     'rotation210', \n",
        "                     'rotation240', \n",
        "                     'rotation270', \n",
        "                     'rotation300', \n",
        "                     'rotation330', \n",
        "                     'flipping0_rotat30','flipping0_rotat60',\n",
        "                     'flipping0_rotat90','flipping0_rotat120',\n",
        "                     'flipping0_rotat150',\n",
        "                     'flipping0_rotat180',\n",
        "                     'flipping0_rotat210','flipping0_rotat240',\n",
        "                     'flipping0_rotat270',\n",
        "                     'flipping0_rotat300','flipping0_rotat330',\n",
        "                     'flipping1_rotat30','flipping1_rotat60',\n",
        "                     'flipping1_rotat90','flipping1_rotat120',\n",
        "                     'flipping1_rotat150',\n",
        "                     'flipping1_rotat180',\n",
        "                     'flipping1_rotat210','flipping1_rotat240',\n",
        "                     'flipping1_rotat270',\n",
        "                     'flipping1_rotat300','flipping1_rotat330',\n",
        "                     'zoom_out08',\n",
        "                     'zoom_out08_rotat30', 'zoom_out08_rotat60',\n",
        "                     'zoom_out08_rotat90',\n",
        "                     'zoom_out08_rotat120',\n",
        "                     'zoom_out08_rotat180','zoom_out08_rotat150',\n",
        "                     'zoom_out08_rotat210','zoom_out08_rotat240',\n",
        "                     'zoom_out08_rotat270',\n",
        "                     'zoom_out08_rotat300',\n",
        "                     'zoom_out08_rotat330',\n",
        "                     'white_noise10',\n",
        "                     'elastic',\n",
        "                     'shifty_100','shifty_-100','shiftx_100','shiftx_-100',\n",
        "                     'shifty_100_90','shifty_100_180','shifty_100_270',\n",
        "                     'shifty_-100_90','shifty_-100_180','shifty_-100_270',\n",
        "                     'shiftx_100_90','shiftx_100_180','shiftx_100_270',\n",
        "                     'shiftx_-100_90','shiftx_-100_180','shiftx_-100_270'\n",
        "                     ])\n",
        "\n",
        "\n",
        "A_gamma_album = ['train', \n",
        "                     'flipping0', \n",
        "                     'flipping1', \n",
        "                     'rotation30', \n",
        "                     'rotation60', \n",
        "                     'rotation90', \n",
        "                     'rotation120', \n",
        "                     'rotation150', \n",
        "                     'rotation180', \n",
        "                     'rotation210', \n",
        "                     'rotation240', \n",
        "                     'rotation270', \n",
        "                     'rotation300', \n",
        "                     'rotation330', \n",
        "                     'flipping0_rotat30','flipping0_rotat60',\n",
        "                     'flipping0_rotat90','flipping0_rotat120',\n",
        "                     'flipping0_rotat150',\n",
        "                     'flipping0_rotat180',\n",
        "                     'flipping0_rotat210','flipping0_rotat240',\n",
        "                     'flipping0_rotat270',\n",
        "                     'flipping0_rotat300','flipping0_rotat330',\n",
        "                     'flipping1_rotat30','flipping1_rotat60',\n",
        "                     'flipping1_rotat90','flipping1_rotat120',\n",
        "                     'flipping1_rotat150',\n",
        "                     'flipping1_rotat180',\n",
        "                     'flipping1_rotat210','flipping1_rotat240',\n",
        "                     'flipping1_rotat270',\n",
        "                     'flipping1_rotat300','flipping1_rotat330',\n",
        "                     'zoom_out08',\n",
        "                     'zoom_out08_rotat30', 'zoom_out08_rotat60',\n",
        "                     'zoom_out08_rotat90',\n",
        "                     'zoom_out08_rotat120',\n",
        "                     'zoom_out08_rotat180','zoom_out08_rotat150',\n",
        "                     'zoom_out08_rotat210','zoom_out08_rotat240',\n",
        "                     'zoom_out08_rotat270',\n",
        "                     'zoom_out08_rotat300',\n",
        "                     'zoom_out08_rotat330',\n",
        "                     'white_noise10',\n",
        "                     'elastic',\n",
        "                     'shifty_100','shifty_-100','shiftx_100','shiftx_-100',\n",
        "                     'shifty_100_90','shifty_100_180','shifty_100_270',\n",
        "                     'shifty_-100_90','shifty_-100_180','shifty_-100_270',\n",
        "                     'shiftx_100_90','shiftx_100_180','shiftx_100_270',\n",
        "                     'shiftx_-100_90','shiftx_-100_180','shiftx_-100_270',\n",
        "                     'gamma_corr05','gamma_corr05_rotation30','gamma_corr05_rotation60',\n",
        "                     'gamma_corr05_rotation90','gamma_corr05_rotation120','gamma_corr05_rotation150',\n",
        "                     'gamma_corr05_rotation180','gamma_corr05_rotation210','gamma_corr05_rotation240',\n",
        "                     'gamma_corr05_rotation270','gamma_corr05_rotation300','gamma_corr05_rotation330',\n",
        "                     'album_elastic','album_grid_dist','album_heavy', 'album_medium', 'album_optical','album_random_crop']\n",
        "\n",
        "B: ['train', \n",
        "                     'flipping0', \n",
        "                     'flipping1', \n",
        "                     'rotation30', \n",
        "                     'rotation60', \n",
        "                     'rotation90', \n",
        "                     'rotation120', \n",
        "                     'rotation150', \n",
        "                     'rotation180', \n",
        "                     'rotation210', \n",
        "                     'rotation240', \n",
        "                     'rotation270', \n",
        "                     'rotation300', \n",
        "                     'rotation330', \n",
        "                     'flipping0_rotat30','flipping0_rotat60',\n",
        "                     'flipping0_rotat90','flipping0_rotat120',\n",
        "                     'flipping0_rotat150',\n",
        "                     'flipping0_rotat180',\n",
        "                     'flipping0_rotat210','flipping0_rotat240',\n",
        "                     'flipping0_rotat270',\n",
        "                     'flipping0_rotat300','flipping0_rotat330',\n",
        "                     'flipping1_rotat30','flipping1_rotat60',\n",
        "                     'flipping1_rotat90','flipping1_rotat120',\n",
        "                     'flipping1_rotat150',\n",
        "                     'flipping1_rotat180',\n",
        "                     'flipping1_rotat210','flipping1_rotat240',\n",
        "                     'flipping1_rotat270',\n",
        "                     'flipping1_rotat300','flipping1_rotat330',\n",
        "                     'zoom_out08',\n",
        "                     'zoom_out08_rotat30', 'zoom_out08_rotat60',\n",
        "                     'zoom_out08_rotat90',\n",
        "                     'zoom_out08_rotat120',\n",
        "                     'zoom_out08_rotat180','zoom_out08_rotat150',\n",
        "                     'zoom_out08_rotat210','zoom_out08_rotat240',\n",
        "                     'zoom_out08_rotat270',\n",
        "                     'zoom_out08_rotat300',\n",
        "                     'zoom_out08_rotat330',\n",
        "                     'white_noise10','white_noise10_90','white_noise10_180','white_noise10_270',\n",
        "                     'elastic',\n",
        "                     'shifty_100','shifty_-100','shiftx_100','shiftx_-100',\n",
        "                     'shifty_100_90','shifty_100_180','shifty_100_270',\n",
        "                     'shifty_-100_90','shifty_-100_180','shifty_-100_270',\n",
        "                     'shiftx_100_90','shiftx_100_180','shiftx_100_270',\n",
        "                     'shiftx_-100_90','shiftx_-100_180','shiftx_-100_270',\n",
        "                     'gamma_corr05','gamma_corr05_rotation30','gamma_corr05_rotation60',\n",
        "                     'gamma_corr05_rotation90','gamma_corr05_rotation120','gamma_corr05_rotation150',\n",
        "                     'gamma_corr05_rotation180','gamma_corr05_rotation210','gamma_corr05_rotation240',\n",
        "                     'gamma_corr05_rotation270','gamma_corr05_rotation300','gamma_corr05_rotation330',\n",
        "                     'album_elastic','album_grid_dist','album_heavy', 'album_medium', 'album_optical','album_random_crop',\n",
        "                     'album_elastic90', 'album_elastic180', 'album_grid_dist90','album_grid_dist180','album_grid_dist270',\n",
        "                     'album_heavy90','album_heavy180','album_heavy270','album_medium90','album_medium180','album_medium270',\n",
        "                     'album_optical90', 'album_optical180', 'album_optical270','album_random_crop2','album_random_crop3','album_random_crop4',\n",
        "                     'blurring3', 'blurring5','dropout010','eq_hist', 'sharpen']"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}